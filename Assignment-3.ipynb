{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "X-cp_kAxCAY2"
   },
   "source": [
    "# Amazon Fine Food Reviews Analysis\n",
    "\n",
    "\n",
    "Data Source: https://www.kaggle.com/snap/amazon-fine-food-reviews <br>\n",
    "\n",
    "EDA: https://nycdatascience.com/blog/student-works/amazon-fine-foods-visualization/\n",
    "\n",
    "\n",
    "The Amazon Fine Food Reviews dataset consists of reviews of fine foods from Amazon.<br>\n",
    "\n",
    "Number of reviews: 568,454<br>\n",
    "Number of users: 256,059<br>\n",
    "Number of products: 74,258<br>\n",
    "Timespan: Oct 1999 - Oct 2012<br>\n",
    "Number of Attributes/Columns in data: 10 \n",
    "\n",
    "Attribute Information:\n",
    "\n",
    "1. Id\n",
    "2. ProductId - unique identifier for the product\n",
    "3. UserId - unqiue identifier for the user\n",
    "4. ProfileName\n",
    "5. HelpfulnessNumerator - number of users who found the review helpful\n",
    "6. HelpfulnessDenominator - number of users who indicated whether they found the review helpful or not\n",
    "7. Score - rating between 1 and 5\n",
    "8. Time - timestamp for the review\n",
    "9. Summary - brief summary of the review\n",
    "10. Text - text of the review\n",
    "\n",
    "\n",
    "#### Objective:\n",
    "Given a review, determine whether the review is positive (Rating of 4 or 5) or negative (rating of 1 or 2).\n",
    "\n",
    "<br>\n",
    "[Q] How to determine if a review is positive or negative?<br>\n",
    "<br> \n",
    "[Ans] We could use the Score/Rating. A rating of 4 or 5 could be cosnidered a positive review. A review of 1 or 2 could be considered negative. A review of 3 is nuetral and ignored. This is an approximate and proxy way of determining the polarity (positivity/negativity) of a review.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 201
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1198,
     "status": "error",
     "timestamp": 1568459387621,
     "user": {
      "displayName": "Applied AI Course",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mC6pMrRYsn22C9tuTEP5-bjFj-F25a3idPwqTuaHQ=s64",
      "userId": "06629147635963609455"
     },
     "user_tz": -330
    },
    "id": "snjMYFygdZ-C",
    "outputId": "fefa78f2-293f-4fa3-9f7d-e01e5b69bfe9"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sparse' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-51e1a92f6585>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mlst\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m6\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m7\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mans\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msparse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcsr_matrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlst\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'sparse' is not defined"
     ]
    }
   ],
   "source": [
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "lst = [1, 2, 3, 4, 5, 6, 7]\n",
    "\n",
    "ans = sparse.csr_matrix(lst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WHC_UQTuCAY4"
   },
   "source": [
    "## Loading the data\n",
    "\n",
    "The dataset is available in two forms\n",
    "1. .csv file\n",
    "2. SQLite Database\n",
    "\n",
    "In order to load the data, We have used the SQLITE dataset as it easier to query the data and visualise the data efficiently.\n",
    "<br> \n",
    "\n",
    "Here as we only want to get the global sentiment of the recommendations (positive or negative), we will purposefully ignore all Scores equal to 3. If the score id above 3, then the recommendation wil be set to \"positive\". Otherwise, it will be set to \"negative\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PvDdRsHgCAY5",
    "outputId": "65b237f2-2ead-4721-f95a-15ed0bb06d04"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "unable to import 'smart_open.gcs', disabling that module\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "\n",
    "import sqlite3\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import string\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "\n",
    "import re\n",
    "# Tutorial about Python regular expressions: https://pymotw.com/2/re/\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.models import KeyedVectors\n",
    "import pickle\n",
    "\n",
    "from tqdm import tqdm\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QOI7X2YgCAY_"
   },
   "source": [
    "# [1]. Reading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3iYH2p1ECAZA",
    "outputId": "3feca330-8e21-4173-ad7c-88eb4d81668e"
   },
   "outputs": [],
   "source": [
    "#establishing the connection\n",
    "conn = sqlite3.connect('database.sqlite')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>ProductId</th>\n",
       "      <th>UserId</th>\n",
       "      <th>ProfileName</th>\n",
       "      <th>HelpfulnessNumerator</th>\n",
       "      <th>HelpfulnessDenominator</th>\n",
       "      <th>Score</th>\n",
       "      <th>Time</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>B001E4KFG0</td>\n",
       "      <td>A3SGXH7AUHU8GW</td>\n",
       "      <td>delmartian</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1303862400</td>\n",
       "      <td>Good Quality Dog Food</td>\n",
       "      <td>I have bought several of the Vitality canned d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>B00813GRG4</td>\n",
       "      <td>A1D87F6ZCVE5NK</td>\n",
       "      <td>dll pa</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1346976000</td>\n",
       "      <td>Not as Advertised</td>\n",
       "      <td>Product arrived labeled as Jumbo Salted Peanut...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>B000LQOCH0</td>\n",
       "      <td>ABXLMWJIXXAIN</td>\n",
       "      <td>Natalia Corres \"Natalia Corres\"</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1219017600</td>\n",
       "      <td>\"Delight\" says it all</td>\n",
       "      <td>This is a confection that has been around a fe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>B000UA0QIQ</td>\n",
       "      <td>A395BORC6FGVXV</td>\n",
       "      <td>Karl</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1307923200</td>\n",
       "      <td>Cough Medicine</td>\n",
       "      <td>If you are looking for the secret ingredient i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>B006K2ZZ7K</td>\n",
       "      <td>A1UQRSCLF8GW1T</td>\n",
       "      <td>Michael D. Bigham \"M. Wassir\"</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1350777600</td>\n",
       "      <td>Great taffy</td>\n",
       "      <td>Great taffy at a great price.  There was a wid...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id   ProductId          UserId                      ProfileName  \\\n",
       "0   1  B001E4KFG0  A3SGXH7AUHU8GW                       delmartian   \n",
       "1   2  B00813GRG4  A1D87F6ZCVE5NK                           dll pa   \n",
       "2   3  B000LQOCH0   ABXLMWJIXXAIN  Natalia Corres \"Natalia Corres\"   \n",
       "3   4  B000UA0QIQ  A395BORC6FGVXV                             Karl   \n",
       "4   5  B006K2ZZ7K  A1UQRSCLF8GW1T    Michael D. Bigham \"M. Wassir\"   \n",
       "\n",
       "   HelpfulnessNumerator  HelpfulnessDenominator  Score        Time  \\\n",
       "0                     1                       1      5  1303862400   \n",
       "1                     0                       0      1  1346976000   \n",
       "2                     1                       1      4  1219017600   \n",
       "3                     3                       3      2  1307923200   \n",
       "4                     0                       0      5  1350777600   \n",
       "\n",
       "                 Summary                                               Text  \n",
       "0  Good Quality Dog Food  I have bought several of the Vitality canned d...  \n",
       "1      Not as Advertised  Product arrived labeled as Jumbo Salted Peanut...  \n",
       "2  \"Delight\" says it all  This is a confection that has been around a fe...  \n",
       "3         Cough Medicine  If you are looking for the secret ingredient i...  \n",
       "4            Great taffy  Great taffy at a great price.  There was a wid...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_data=pd.read_sql_query(\"select * from Reviews WHERE Score!=3 limit 5000\",conn)\n",
    "filtered_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "I1jf03kECAZF"
   },
   "outputs": [],
   "source": [
    "display = pd.read_sql_query(\"\"\"\n",
    "SELECT UserId, ProductId, ProfileName, Time, Score, Text, COUNT(*)\n",
    "FROM Reviews\n",
    "GROUP BY UserId\n",
    "HAVING COUNT(*)>1\n",
    "\"\"\", conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ja8xSefOCAZH",
    "outputId": "2cbd0705-618b-47cf-ce18-f3d0d4063cbf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(80668, 7)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UserId</th>\n",
       "      <th>ProductId</th>\n",
       "      <th>ProfileName</th>\n",
       "      <th>Time</th>\n",
       "      <th>Score</th>\n",
       "      <th>Text</th>\n",
       "      <th>COUNT(*)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>#oc-R115TNMSPFT9I7</td>\n",
       "      <td>B005ZBZLT4</td>\n",
       "      <td>Breyton</td>\n",
       "      <td>1331510400</td>\n",
       "      <td>2</td>\n",
       "      <td>Overall its just OK when considering the price...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>#oc-R11D9D7SHXIJB9</td>\n",
       "      <td>B005HG9ESG</td>\n",
       "      <td>Louis E. Emory \"hoppy\"</td>\n",
       "      <td>1342396800</td>\n",
       "      <td>5</td>\n",
       "      <td>My wife has recurring extreme muscle spasms, u...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>#oc-R11DNU2NBKQ23Z</td>\n",
       "      <td>B005ZBZLT4</td>\n",
       "      <td>Kim Cieszykowski</td>\n",
       "      <td>1348531200</td>\n",
       "      <td>1</td>\n",
       "      <td>This coffee is horrible and unfortunately not ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>#oc-R11O5J5ZVQE25C</td>\n",
       "      <td>B005HG9ESG</td>\n",
       "      <td>Penguin Chick</td>\n",
       "      <td>1346889600</td>\n",
       "      <td>5</td>\n",
       "      <td>This will be the bottle that you grab from the...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>#oc-R12KPBODL2B5ZD</td>\n",
       "      <td>B007OSBEV0</td>\n",
       "      <td>Christopher P. Presta</td>\n",
       "      <td>1348617600</td>\n",
       "      <td>1</td>\n",
       "      <td>I didnt like this coffee. Instead of telling y...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               UserId   ProductId             ProfileName        Time  Score  \\\n",
       "0  #oc-R115TNMSPFT9I7  B005ZBZLT4                 Breyton  1331510400      2   \n",
       "1  #oc-R11D9D7SHXIJB9  B005HG9ESG  Louis E. Emory \"hoppy\"  1342396800      5   \n",
       "2  #oc-R11DNU2NBKQ23Z  B005ZBZLT4        Kim Cieszykowski  1348531200      1   \n",
       "3  #oc-R11O5J5ZVQE25C  B005HG9ESG           Penguin Chick  1346889600      5   \n",
       "4  #oc-R12KPBODL2B5ZD  B007OSBEV0   Christopher P. Presta  1348617600      1   \n",
       "\n",
       "                                                Text  COUNT(*)  \n",
       "0  Overall its just OK when considering the price...         2  \n",
       "1  My wife has recurring extreme muscle spasms, u...         3  \n",
       "2  This coffee is horrible and unfortunately not ...         2  \n",
       "3  This will be the bottle that you grab from the...         3  \n",
       "4  I didnt like this coffee. Instead of telling y...         2  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(display.shape)\n",
    "display.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "u5ctUTW-CAZK",
    "outputId": "41439570-0ff9-44bb-9c05-e87bcb3dd6b7"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UserId</th>\n",
       "      <th>ProductId</th>\n",
       "      <th>ProfileName</th>\n",
       "      <th>Time</th>\n",
       "      <th>Score</th>\n",
       "      <th>Text</th>\n",
       "      <th>COUNT(*)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>80638</th>\n",
       "      <td>AZY10LLTJ71NX</td>\n",
       "      <td>B001ATMQK2</td>\n",
       "      <td>undertheshrine \"undertheshrine\"</td>\n",
       "      <td>1296691200</td>\n",
       "      <td>5</td>\n",
       "      <td>I bought this 6 pack because for the price tha...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              UserId   ProductId                      ProfileName        Time  \\\n",
       "80638  AZY10LLTJ71NX  B001ATMQK2  undertheshrine \"undertheshrine\"  1296691200   \n",
       "\n",
       "       Score                                               Text  COUNT(*)  \n",
       "80638      5  I bought this 6 pack because for the price tha...         5  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "display[display['UserId']=='AZY10LLTJ71NX']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tiaXnkZxCAZO",
    "outputId": "0bbd60e6-e66b-4f20-9060-bf0cfe143b1f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "393063"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "display['COUNT(*)'].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TX5b3dc5CAZS"
   },
   "source": [
    "#  Exploratory Data Analysis\n",
    "\n",
    "## [2] Data Cleaning: Deduplication\n",
    "\n",
    "It is observed (as shown in the table below) that the reviews data had many duplicate entries. Hence it was necessary to remove duplicates in order to get unbiased results for the analysis of the data.  Following is an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4jW_0WxCCAZT",
    "outputId": "4e526ab2-98f3-46ae-93dc-3e061cb06d59",
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>ProductId</th>\n",
       "      <th>UserId</th>\n",
       "      <th>ProfileName</th>\n",
       "      <th>HelpfulnessNumerator</th>\n",
       "      <th>HelpfulnessDenominator</th>\n",
       "      <th>Score</th>\n",
       "      <th>Time</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>78445</td>\n",
       "      <td>B000HDL1RQ</td>\n",
       "      <td>AR5J8UI46CURR</td>\n",
       "      <td>Geetha Krishnan</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1199577600</td>\n",
       "      <td>LOACKER QUADRATINI VANILLA WAFERS</td>\n",
       "      <td>DELICIOUS WAFERS. I FIND THAT EUROPEAN WAFERS ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>138317</td>\n",
       "      <td>B000HDOPYC</td>\n",
       "      <td>AR5J8UI46CURR</td>\n",
       "      <td>Geetha Krishnan</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1199577600</td>\n",
       "      <td>LOACKER QUADRATINI VANILLA WAFERS</td>\n",
       "      <td>DELICIOUS WAFERS. I FIND THAT EUROPEAN WAFERS ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>138277</td>\n",
       "      <td>B000HDOPYM</td>\n",
       "      <td>AR5J8UI46CURR</td>\n",
       "      <td>Geetha Krishnan</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1199577600</td>\n",
       "      <td>LOACKER QUADRATINI VANILLA WAFERS</td>\n",
       "      <td>DELICIOUS WAFERS. I FIND THAT EUROPEAN WAFERS ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>73791</td>\n",
       "      <td>B000HDOPZG</td>\n",
       "      <td>AR5J8UI46CURR</td>\n",
       "      <td>Geetha Krishnan</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1199577600</td>\n",
       "      <td>LOACKER QUADRATINI VANILLA WAFERS</td>\n",
       "      <td>DELICIOUS WAFERS. I FIND THAT EUROPEAN WAFERS ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>155049</td>\n",
       "      <td>B000PAQ75C</td>\n",
       "      <td>AR5J8UI46CURR</td>\n",
       "      <td>Geetha Krishnan</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1199577600</td>\n",
       "      <td>LOACKER QUADRATINI VANILLA WAFERS</td>\n",
       "      <td>DELICIOUS WAFERS. I FIND THAT EUROPEAN WAFERS ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Id   ProductId         UserId      ProfileName  HelpfulnessNumerator  \\\n",
       "0   78445  B000HDL1RQ  AR5J8UI46CURR  Geetha Krishnan                     2   \n",
       "1  138317  B000HDOPYC  AR5J8UI46CURR  Geetha Krishnan                     2   \n",
       "2  138277  B000HDOPYM  AR5J8UI46CURR  Geetha Krishnan                     2   \n",
       "3   73791  B000HDOPZG  AR5J8UI46CURR  Geetha Krishnan                     2   \n",
       "4  155049  B000PAQ75C  AR5J8UI46CURR  Geetha Krishnan                     2   \n",
       "\n",
       "   HelpfulnessDenominator  Score        Time  \\\n",
       "0                       2      5  1199577600   \n",
       "1                       2      5  1199577600   \n",
       "2                       2      5  1199577600   \n",
       "3                       2      5  1199577600   \n",
       "4                       2      5  1199577600   \n",
       "\n",
       "                             Summary  \\\n",
       "0  LOACKER QUADRATINI VANILLA WAFERS   \n",
       "1  LOACKER QUADRATINI VANILLA WAFERS   \n",
       "2  LOACKER QUADRATINI VANILLA WAFERS   \n",
       "3  LOACKER QUADRATINI VANILLA WAFERS   \n",
       "4  LOACKER QUADRATINI VANILLA WAFERS   \n",
       "\n",
       "                                                Text  \n",
       "0  DELICIOUS WAFERS. I FIND THAT EUROPEAN WAFERS ...  \n",
       "1  DELICIOUS WAFERS. I FIND THAT EUROPEAN WAFERS ...  \n",
       "2  DELICIOUS WAFERS. I FIND THAT EUROPEAN WAFERS ...  \n",
       "3  DELICIOUS WAFERS. I FIND THAT EUROPEAN WAFERS ...  \n",
       "4  DELICIOUS WAFERS. I FIND THAT EUROPEAN WAFERS ...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "display= pd.read_sql_query(\"\"\"\n",
    "SELECT *\n",
    "FROM Reviews\n",
    "WHERE Score != 3 AND UserId=\"AR5J8UI46CURR\"\n",
    "ORDER BY ProductID\n",
    "\"\"\", conn)\n",
    "display.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BzVTlHiMCAZV"
   },
   "source": [
    "As can be seen above the same user has multiple reviews of the with the same values for HelpfulnessNumerator, HelpfulnessDenominator, Score, Time, Summary and Text  and on doing analysis it was found that <br>\n",
    "<br> \n",
    "ProductId=B000HDOPZG was Loacker Quadratini Vanilla Wafer Cookies, 8.82-Ounce Packages (Pack of 8)<br>\n",
    "<br> \n",
    "ProductId=B000HDL1RQ was Loacker Quadratini Lemon Wafer Cookies, 8.82-Ounce Packages (Pack of 8) and so on<br>\n",
    "\n",
    "It was inferred after analysis that reviews with same parameters other than ProductId belonged to the same product just having different flavour or quantity. Hence in order to reduce redundancy it was decided to eliminate the rows having same parameters.<br>\n",
    "\n",
    "The method used for the same was that we first sort the data according to ProductId and then just keep the first similar product review and delelte the others. for eg. in the above just the review for ProductId=B000HDL1RQ remains. This method ensures that there is only one representative for each product and deduplication without sorting would lead to possibility of different representatives still existing for the same product."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DGy2NM7BCAZX"
   },
   "outputs": [],
   "source": [
    "#Sorting data according to ProductId in ascending order\n",
    "sorted_data=filtered_data.sort_values('ProductId', axis=0, ascending=True, inplace=False, kind='quicksort', na_position='last')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8b-O13XVCAZZ",
    "outputId": "12b254d4-826d-4cfc-bb6d-455f4d5b2a4f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4986, 10)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Deduplication of entries\n",
    "final=sorted_data.drop_duplicates(subset={\"UserId\",\"ProfileName\",\"Time\",\"Text\"}, keep='first', inplace=False)\n",
    "final.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "S72Yh-rHCAZc",
    "outputId": "146c067f-081c-4e26-f527-71442ff83b8d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "99.72"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Checking to see how much % of data still remains\n",
    "(final['Id'].size*1.0)/(filtered_data['Id'].size*1.0)*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LO5nLKeFCAZf"
   },
   "source": [
    "<b>Observation:-</b> It was also seen that in two rows given below the value of HelpfulnessNumerator is greater than HelpfulnessDenominator which is not practically possible hence these two rows too are removed from calcualtions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "L9z5lrsiCAZh",
    "outputId": "1a0dfa7c-62f4-4469-a97b-38f77fa3b2ab"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>ProductId</th>\n",
       "      <th>UserId</th>\n",
       "      <th>ProfileName</th>\n",
       "      <th>HelpfulnessNumerator</th>\n",
       "      <th>HelpfulnessDenominator</th>\n",
       "      <th>Score</th>\n",
       "      <th>Time</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>64422</td>\n",
       "      <td>B000MIDROQ</td>\n",
       "      <td>A161DK06JJMCYF</td>\n",
       "      <td>J. E. Stephens \"Jeanne\"</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1224892800</td>\n",
       "      <td>Bought This for My Son at College</td>\n",
       "      <td>My son loves spaghetti so I didn't hesitate or...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>44737</td>\n",
       "      <td>B001EQ55RW</td>\n",
       "      <td>A2V0I904FH7ABY</td>\n",
       "      <td>Ram</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1212883200</td>\n",
       "      <td>Pure cocoa taste with crunchy almonds inside</td>\n",
       "      <td>It was almost a 'love at first bite' - the per...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Id   ProductId          UserId              ProfileName  \\\n",
       "0  64422  B000MIDROQ  A161DK06JJMCYF  J. E. Stephens \"Jeanne\"   \n",
       "1  44737  B001EQ55RW  A2V0I904FH7ABY                      Ram   \n",
       "\n",
       "   HelpfulnessNumerator  HelpfulnessDenominator  Score        Time  \\\n",
       "0                     3                       1      5  1224892800   \n",
       "1                     3                       2      4  1212883200   \n",
       "\n",
       "                                        Summary  \\\n",
       "0             Bought This for My Son at College   \n",
       "1  Pure cocoa taste with crunchy almonds inside   \n",
       "\n",
       "                                                Text  \n",
       "0  My son loves spaghetti so I didn't hesitate or...  \n",
       "1  It was almost a 'love at first bite' - the per...  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "display= pd.read_sql_query(\"\"\"\n",
    "SELECT *\n",
    "FROM Reviews\n",
    "WHERE Score != 3 AND Id=44737 OR Id=64422\n",
    "ORDER BY ProductID\n",
    "\"\"\", conn)\n",
    "\n",
    "display.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8Tphk1piCAZk"
   },
   "outputs": [],
   "source": [
    "final=final[final.HelpfulnessNumerator<=final.HelpfulnessDenominator]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8TpsGDdJCAZm",
    "outputId": "287c6c08-d222-4848-b677-c9a5e769d0b1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4986, 10)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "5    3412\n",
       "4     766\n",
       "1     502\n",
       "2     306\n",
       "Name: Score, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Before starting the next phase of preprocessing lets see the number of entries left\n",
    "print(final.shape)\n",
    "\n",
    "#How many positive and negative reviews are present in our dataset?\n",
    "final['Score'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RxBsuBylCAZr"
   },
   "source": [
    "# [3].  Text Preprocessing.\n",
    "\n",
    "Now that we have finished deduplication our data requires some preprocessing before we go on further with analysis and making the prediction model.\n",
    "\n",
    "Hence in the Preprocessing phase we do the following in the order below:-\n",
    "\n",
    "1. Begin by removing the html tags\n",
    "2. Remove any punctuations or limited set of special characters like , or . or # etc.\n",
    "3. Check if the word is made up of english letters and is not alpha-numeric\n",
    "4. Check to see if the length of the word is greater than 2 (as it was researched that there is no adjective in 2-letters)\n",
    "5. Convert the word to lowercase\n",
    "6. Remove Stopwords\n",
    "7. Finally Snowball Stemming the word (it was obsereved to be better than Porter Stemming)<br>\n",
    "\n",
    "After which we collect the words used to describe positive and negative reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "laOGMFB7CAZt",
    "outputId": "49d82795-cea4-4695-9834-45978266f6f4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thirty bucks?\n",
      "==================================================\n",
      "Best sour cream & onion chip I've had\n",
      "==================================================\n",
      "Are We Reviewing Our Mistakes Or These Cookies?\n",
      "==================================================\n",
      "caribou\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "# printing some random reviews\n",
    "sent_0 = final['Summary'].values[0]\n",
    "print(sent_0)\n",
    "print(\"=\"*50)\n",
    "\n",
    "sent_1000 = final['Summary'].values[1000]\n",
    "print(sent_1000)\n",
    "print(\"=\"*50)\n",
    "\n",
    "sent_1500 = final['Summary'].values[1500]\n",
    "print(sent_1500)\n",
    "print(\"=\"*50)\n",
    "\n",
    "sent_4900 = final['Summary'].values[4900]\n",
    "print(sent_4900)\n",
    "print(\"=\"*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MvD0JaQ9CAZx",
    "outputId": "dcc683d4-6014-4430-fb91-f9526bca4475"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thirty bucks?\n"
     ]
    }
   ],
   "source": [
    "# remove urls from text python: https://stackoverflow.com/a/40823105/4084039\n",
    "sent_0 = re.sub(r\"http\\S+\", \"\", sent_0)\n",
    "sent_1000 = re.sub(r\"http\\S+\", \"\", sent_1000)\n",
    "sent_150 = re.sub(r\"http\\S+\", \"\", sent_1500)\n",
    "sent_4900 = re.sub(r\"http\\S+\", \"\", sent_4900)\n",
    "\n",
    "print(sent_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Liu2zNFLCAZ0",
    "outputId": "f66770ef-17d3-4a99-df7f-75242858701d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thirty bucks?\n",
      "==================================================\n",
      "Best sour cream & onion chip I've had\n",
      "==================================================\n",
      "Are We Reviewing Our Mistakes Or These Cookies?\n",
      "==================================================\n",
      "caribou\n"
     ]
    }
   ],
   "source": [
    "# https://stackoverflow.com/questions/16206380/python-beautifulsoup-how-to-remove-all-tags-from-an-element\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "\n",
    "soup = BeautifulSoup(sent_0, 'lxml')\n",
    "text = soup.get_text()\n",
    "print(text)\n",
    "print(\"=\"*50)\n",
    "\n",
    "\n",
    "soup = BeautifulSoup(sent_1000, 'lxml')\n",
    "text = soup.get_text()\n",
    "print(text)\n",
    "print(\"=\"*50)\n",
    "\n",
    "\n",
    "soup = BeautifulSoup(sent_1500, 'lxml')\n",
    "text = soup.get_text()\n",
    "print(text)\n",
    "print(\"=\"*50)\n",
    "\n",
    "\n",
    "soup = BeautifulSoup(sent_4900, 'lxml')\n",
    "text = soup.get_text()\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lNHWbzBaCAZ3"
   },
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/a/47091490/4084039\n",
    "import re\n",
    "\n",
    "def decontracted(phrase):\n",
    "    # specific\n",
    "    phrase = re.sub(r\"won't\", \"will not\", phrase)\n",
    "    phrase = re.sub(r\"can\\'t\", \"can not\", phrase)\n",
    "\n",
    "    # general\n",
    "    phrase = re.sub(r\"n\\'t\", \" not\", phrase)\n",
    "    phrase = re.sub(r\"\\'re\", \" are\", phrase)\n",
    "    phrase = re.sub(r\"\\'s\", \" is\", phrase)\n",
    "    phrase = re.sub(r\"\\'d\", \" would\", phrase)\n",
    "    phrase = re.sub(r\"\\'ll\", \" will\", phrase)\n",
    "    phrase = re.sub(r\"\\'t\", \" not\", phrase)\n",
    "    phrase = re.sub(r\"\\'ve\", \" have\", phrase)\n",
    "    phrase = re.sub(r\"\\'m\", \" am\", phrase)\n",
    "    return phrase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "y7v1fmngCAZ5",
    "outputId": "22e3fcb6-c2e6-4c92-be48-f65543b1140f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Are We Reviewing Our Mistakes Or These Cookies?\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "sent_1500 = decontracted(sent_1500)\n",
    "print(sent_1500)\n",
    "print(\"=\"*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jKIBLrAjCAZ7",
    "outputId": "376f1e55-511a-4352-c345-a39f1d2a2224"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thirty bucks?\n"
     ]
    }
   ],
   "source": [
    "#remove words with numbers python: https://stackoverflow.com/a/18082370/4084039\n",
    "sent_0 = re.sub(\"\\S*\\d\\S*\", \"\", sent_0).strip()\n",
    "print(sent_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sU3eY6geCAZ9",
    "outputId": "90d91c93-0d77-47c0-e496-77d1611a86fb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Are We Reviewing Our Mistakes Or These Cookies \n"
     ]
    }
   ],
   "source": [
    "#remove spacial character: https://stackoverflow.com/a/5843547/4084039\n",
    "sent_1500 = re.sub('[^A-Za-z0-9]+', ' ', sent_1500)\n",
    "print(sent_1500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Xsr4xHkJCAaA"
   },
   "outputs": [],
   "source": [
    "# https://gist.github.com/sebleier/554280\n",
    "# we are removing the words from the stop words list: 'no', 'nor', 'not'\n",
    "# <br /><br /> ==> after the above steps, we are getting \"br br\"\n",
    "# we are including them into stop words list\n",
    "# instead of <br /> if we have <br/> these tags would have revmoved in the 1st step\n",
    "\n",
    "stopwords= set(['br', 'the', 'i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\",\\\n",
    "            \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', \\\n",
    "            'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their',\\\n",
    "            'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', \\\n",
    "            'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', \\\n",
    "            'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', \\\n",
    "            'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after',\\\n",
    "            'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further',\\\n",
    "            'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more',\\\n",
    "            'most', 'other', 'some', 'such', 'only', 'own', 'same', 'so', 'than', 'too', 'very', \\\n",
    "            's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', \\\n",
    "            've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn',\\\n",
    "            \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn',\\\n",
    "            \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", \\\n",
    "            'won', \"won't\", 'wouldn', \"wouldn't\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MgsJ09NpCAaB",
    "outputId": "1d7ef7e7-d03e-4bff-850a-a2aef70af7d9"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 4986/4986 [00:04<00:00, 1055.42it/s]\n"
     ]
    }
   ],
   "source": [
    "# Combining all the above stundents \n",
    "from tqdm import tqdm\n",
    "preprocessed_reviews = []\n",
    "# tqdm is for printing the status bar\n",
    "for sentance in tqdm(final['Text'].values):\n",
    "    sentance = re.sub(r\"http\\S+\", \"\", sentance)\n",
    "    sentance = BeautifulSoup(sentance, 'lxml').get_text()\n",
    "    sentance = decontracted(sentance)\n",
    "    sentance = re.sub(\"\\S*\\d\\S*\", \"\", sentance).strip()\n",
    "    sentance = re.sub('[^A-Za-z]+', ' ', sentance)\n",
    "    # https://gist.github.com/sebleier/554280\n",
    "    sentance = ' '.join(e.lower() for e in sentance.split() if e.lower() not in stopwords)\n",
    "    preprocessed_reviews.append(sentance.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "f_zfwXXWCAaE",
    "outputId": "a8ba4cbf-3a4c-4447-f06a-2b639e1a5f88"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'wow far two two star reviews one obviously no idea ordering wants crispy cookies hey sorry reviews nobody good beyond reminding us look ordering chocolate oatmeal cookies not like combination not order type cookie find combo quite nice really oatmeal sort calms rich chocolate flavor gives cookie sort coconut type consistency let also remember tastes differ given opinion soft chewy cookies advertised not crispy cookies blurb would say crispy rather chewy happen like raw cookie dough however not see taste like raw cookie dough soft however confusion yes stick together soft cookies tend not individually wrapped would add cost oh yeah chocolate chip cookies tend somewhat sweet want something hard crisp suggest nabiso ginger snaps want cookie soft chewy tastes like combination chocolate oatmeal give try place second order'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessed_reviews[1500]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tmeU-LoVCAaI"
   },
   "source": [
    "<h2><font color='red'>[3.2] Preprocess Summary</font></h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wtJ2hcy9CAaI"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "******* Summaries with numbers***********\n",
      "\n",
      "Yummy!\n",
      "==================================================\n",
      "cook & serve choc. fudge pudding\n",
      "==================================================\n",
      "Acceptable & inexpensive, but GREAT when cold brewed!\n",
      "==================================================\n",
      "\n",
      "******* Summaries with numbers***********\n",
      "\n",
      "50 calories of yumminess\n",
      "==================================================\n",
      "White Stevia 12 Oz Pwdr\n",
      "==================================================\n",
      "KEEBLER SOFT BATCH CHOCOLATE CHIP COOKIES 15-OUNCE(PACK OF 6)\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "## Similartly you can do preprocessing for review summary also.\n",
    "\n",
    "\n",
    "#checking for any \n",
    "for count,i in enumerate(final['Summary']):\n",
    "    a=re.search(r\"http\\S+\",i)\n",
    "    if a!=None:\n",
    "        print(count, a)\n",
    "\n",
    "# printing some random Summary\n",
    "\n",
    "#for count,i in enumerate(final['Summary']):\n",
    "#    a=re.search(r'[^A-Za-z0-9]+',i)\n",
    "#    if a!=None:\n",
    "#        print(count, a)\n",
    "\n",
    "print(\"\\n******* Summaries with numbers***********\\n\")\n",
    "    \n",
    "summary_292 = final['Summary'].values[292]\n",
    "print(summary_292)\n",
    "print(\"=\"*50)\n",
    "\n",
    "summary_345  = final['Summary'].values[345]\n",
    "print(summary_345)\n",
    "print(\"=\"*50)\n",
    "\n",
    "summary_3073= final['Summary'].values[3073]\n",
    "print(summary_3073)\n",
    "print(\"=\"*50)\n",
    "\n",
    "print(\"\\n******* Summaries with numbers***********\\n\")\n",
    "\n",
    "#checking for numbers\n",
    "\n",
    "#for count,i in enumerate(final['Summary']):\n",
    "#    a=re.search(r'\\S*\\d\\S*',i)\n",
    "#    if a!=None:\n",
    "#        print(count, a)\n",
    "\n",
    "\n",
    "summary_530 =final['Summary'].values[530]\n",
    "print(summary_530)\n",
    "print(\"=\"*50)\n",
    "\n",
    "summary_174 = final['Summary'].values[174]\n",
    "print(summary_174)\n",
    "print(\"=\"*50)\n",
    "\n",
    "summary_4222= final['Summary'].values[4222]\n",
    "print(summary_4222)\n",
    "print(\"=\"*50)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary: \n",
    "\n",
    "1.No Hyperlinks are present\n",
    "\n",
    "2.found Special charecters and Numbers(digits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████| 4986/4986 [00:00<00:00, 24946.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['thirty bucks', 'flies begone', 'wow make islickers', 'great product', 'good stuff', 'premium quality dog food', 'cats love', 'nice big pieces big almond flavor', 'summer treat fat free guilt free', 'not buy product unless looking shredded coconut', 'little flavor', 'staple house', 'favorite quick meal solution', 'best hot sauce taco sauce available america', 'pico pica best', 'stuff', 'everyone saying pico pica true', 'not edible', 'shining star', 'inexpensive alternative gold leaf', 'create exquisite cake decorations', 'gold dust awesome', 'perfect sons cake', 'really cute made great golf cake', 'golf set', 'cake topper', 'fantastic', 'adzuki beans', 'yum', 'yummy', 'beans', 'fabulous', 'awesome', 'mae ploy chili sauce', 'move outta way ketchup barbecue sauce', 'mae ploy sauce great stuff', 'oh', 'pei wei pf changs house', 'great sauce', 'guess minority', 'classic condiment', 'highly addicting', 'put meats', 'love', 'yum', 'yummy sauce', 'great sauce', 'restaurants serve', 'favorite dipping sauce', 'best sauce world', 'best sauce ever', 'perfect condiment', 'great taste', 'thai chili sauce', 'taste treat substitute bbq sauce', 'really nice sweet bit kick', 'great sauce', 'best no doubt', 'really good sauce', 'crowd best purpose sauce ever', 'ca not afford trip thailand', 'pleasure dining', 'fantastic', 'goes great many dishes', 'favorite sauce tijuana flats', 'folks right', 'sweet right delish', 'ultimate sweet sour sauce', 'really different really good', 'taste great', 'nobody better', 'great product', 'absolutely love', 'great sauce w extreme heat', 'fave', 'stuff want', 'sweeeeet hot', 'great jerky', 'chocolate italian kisses need say', 'incorrect packaging', 'yum', 'treat', 'great buy', 'smooth rich blend', 'wonderful tea', 'favorite tea time', 'perfect gift', 'best hot sauce world', 'smells', 'standard', 'sad outcome', 'miracle', 'way salty', 'exaclty ordered', 'lovely juniper berries', 'filler food empty leaves cat always needing', 'worst snap lock reseal ever made', 'kitty junk food', 'worked well', 'keeps cats happy healthy', 'not minced ground beef', 'product corn not waste money', 'loves', 'cats refused eat', 'tea ages', 'comforting vegetable soup without veggies', 'great tummy tamer', 'yummy', 'hooked', 'good tea prompt service', 'tasty good price organic', 'best white gravy', 'pioneer gravy great', 'yeeeee hawww', 'wonderful gravy', 'charlee bears', 'dog treats', 'great low calorie training treats', 'amazing', 'best training treat', 'feel good giving treats pups', 'great low calorie treat overweight dogs training treats', 'smells great', 'scrumptious', 'diet peach snapple delivered safely quickly', 'yep diet', 'awful', 'superlative store bought cookies hard find', 'add skim milk banana blueberries wheat germ multi vitamin healthier choice', 'passover treat', 'delicious treat', 'wow stuff incredible', 'much cheaper penta website', 'rejuvenating water', 'cheaper penta com', 'wash record collection', 'best roast ever', 'french roast n bags', 'franch best', 'great taste', 'happy customer', 'great coffee', 'excellent coffee', 'costa rican export coffee', 'coffee amazon com', 'vintage tasting coffee', 'fantastic coffee', 'best coffee ever', 'aunt favorite', 'excellent exactly expected', 'good stuff', 'best', 'great beans', 'sweeter sugar', 'best alternative sugar', 'great taste great value', 'world best sweetener', 'best stevia product found', 'sweet stuff', 'great product', 'best ever', 'best taste ever', 'great product', 'best stevia', 'love stuff', 'sweetener use', 'perfectly naturally sweet', 'best tasting', 'great taste safe natural', 'great product no bitter taste wo not spike insulin', 'also look packets', 'love stuff', 'tastes great iced drinks', 'nunaturals nustevia great', 'white stevia oz pwdr', 'excellent alternative artificial sweetners', 'best stevia', 'get healthy live better longer', 'best tasting stevia', 'best stevia product ever used', 'great sweetener', 'used favorite', 'new favorite sweetener', 'sweetly satisfying', 'great taste zero calories', 'easter basket', 'well received treat', 'healthy treat dogs allergies', 'corgi approved', 'one two market', 'sickness death', 'funny taste', 'loved oats', 'mm mm oats', 'good oatmeal second bag', 'excellent quality product fast delivery', 'great way order', 'rave review rolled oats', 'good quality delivered time human edible', 'boy bubble gum', 'buble gun cigars real cigars might tasted better', 'everything iv e ordered far', 'fun daughter', 'great announcement non smokers', 'stale cigars', 'nice', 'expensive buy', 'price right', 'good mix looseleaf teas', 'favorite crackers', 'best tasking crackers ever', 'skyflakes', 'satisfied customer', 'crispy fresh', 'color discrepancy', 'soooo tiny', 'perfect', 'excellent service product', 'boring boring boring', 'fortune cookies', 'fortune cookies', 'good', 'awsome', 'bed', 'great cookie lots fun', 'pleased customer', 'feliciaflan', 'really helps', 'no effect sinus sufferer', 'not work', 'not nothing', 'tea works feel much better', 'sinus buster tea', 'real sinus buster', 'interesting taste slow relief sinus pressure', 'sinus help', 'product works', 'not work', 'make tea strong', 'great stuff', 'wonderful', 'mucus drainage', 'skeptical', 'empty tea bags beware', 'absolute recommend product', 'sinus', 'sinus relief', 'effective tea', 'popular snackfood night club', 'utz pub mix hit even iraq', 'almost good', 'great snack however', 'delicious snack', 'contains msg', 'mixed snacks gods', 'great product would buy', 'great snack', 'wonderful blend flavors', 'hard find excellent snack', 'best bar mix available', 'pub mix addicting', 'awesome', 'mc cormicks alfredo sauce', 'rich belgian chocolate', 'coconut bars', 'jittery lacks body', 'cats love diet food better regular food', 'cats not fans new food', 'great fat cats senior citizens', 'nearly killed cats', 'changed formula makes cats sick', 'cat loves', 'better average expensive average', 'soy dairy free shortening', 'works great better crisco', 'great tortillas', 'formula terrible', 'shame use much corn syrup babies', 'solves colic within one day corn syrup based', 'first ingredient corn syrup', 'costco b oz way cheaper', 'similac sensitive', 'reduced spit happier baby', 'great aroma not like coffee', 'good', 'easy setup nice design', 'nicely thought kit temporary grazing etc', 'good corral horse maybe additional electric tape', 'great short term fencing', 'easy set', 'easy assembly great alpacas', 'works us', 'yummy', 'melted', 'vitakraft carob drops', 'stopped doggie accidents', 'fabulous', 'vitakraft carob dog treats', 'yummy', 'dogs love', 'dont', 'dog eats stuff', 'vitakraft best', 'buffy gives five paws', 'dog treats', 'choco drops', 'best treat ever', 'sugar bad dogs first ingredient sugar', 'sweet soothing', 'great mix painful', 'great gift idea', 'spicey flavors', 'good stuff', 'wow hot', 'not champions', 'excellent selection sauces', 'good hot stuff', 'great gift', 'great kit great price wood holder not good', 'pschologically better peanuts', 'satisfying', 'excellent crisps', 'not shabby', 'yummy', 'inconsistent quality', 'terrible', 'dissatisfied', 'soy crisps awesome snack', 'sugar free salty goodness', 'good healthy', 'delicious packaging could smaller', 'soy crisp', 'delicious', 'one favorites', 'love soy crisps', 'save money', 'fantastic taste good', 'reboot snack processors', 'pretty good', 'crunchy no guilt snack', 'makes everything better', 'favorite tea', 'best tea ever', 'cents per ounce twice regular price', 'pudding', 'cook serve choc fudge pudding', 'great dessert', 'great keep hand desserts', 'pudding', 'excellent base mix', 'wonderful dessert', 'good cravings', 'excellent product', 'nice morning coffee', 'great taste', 'best graham crackers no longer available', 'every bit good remembered', 'freshest bit honey find', 'sticky fingers', 'yum', 'bit honey', 'like kid', 'fresh', 'still', 'ole time candy love', 'love taffy', 'bit honey', 'candy tasted good', 'fresh soft candy', 'yummy', 'great product great price', 'gotta love wonka', 'mmm fresh candy', 'classic candy', 'exactly ordered plain simple', 'excellent', 'excellent', 'yay barley', 'pretzel', 'easy delicious', 'delicious', 'gluten free goodness', 'tasty easy', 'really good', 'quick yummy unusual soup', 'artificial flavor', 'great gluten free quick fix meal', 'not bad not reorder', 'tasteless mess', 'horrible smell', 'taste thai', 'not much', 'taste thai coconut ginger soup', 'eh', 'good thai green curry', 'yum', 'tasty easy', 'hot hot hot', 'curry paste', 'tons flavor spicy excellent', 'must healthy life', 'good seeds gravel bits', 'good product', 'great conflakes', 'good almost anything', 'good', 'healthy goodness', 'great stuff', 'happy purchase', 'great flaxseed delivery service', 'healthy', 'good seeds', 'organic golden', 'red mill', 'fiber packed nutrient rich', 'great source', 'bird seed', 'product fine', 'flax seed recommended brand', 'lovely seeds cereal baking yogurt', 'excellent quality', 'good stuff', 'best flaxseeds ever', 'bob red mill organic golden flaxseed', 'best way eat sunflower seeds', 'best best nut cluster snacks ever', 'tastes great pkg says made china not buy', 'health food china doubtful', 'delicious', 'great taste without high fructose corn syrup', 'carbon footprint product', 'fantastic', 'product not made china', 'quality', 'great taste honestly goes inside read', 'mrs may almonds make days', 'mrs mays almond crunch', 'delicious', 'mrs mays anonymous', 'great snack', 'made china', 'delicious addictive healthy', 'delicious healthy snack', 'good evaporate', 'made china still enjoy', 'sweet nutty', 'love mrs may products', 'quality seems slipping', 'product made china', 'love nut', 'great almond crunch', 'good stuff', 'good snack everyone', 'highest protein', 'yummy', 'mrs may pumpkin crunch terrific', 'tasty light', 'great product', 'pasta', 'daughter favorite food', 'new fave pasta', 'theres better curry paste', 'good value good taste', 'authentic taste easy prepare', 'like restaurant', 'goodness', 'delicious', 'effective soothing tea kids throat', 'oily lacks flavor', 'surprisingly flavorful dine friend', 'tatsy', 'pretty good stuff', 'flavorless sludge', 'really good', 'satay noodles', 'tasty', 'excellent rice crackers', 'best crackers ever', 'great', 'wrong product', 'great snack', 'crispy crackers w gluten', 'excellent snack', 'loved', 'excellent non gluten product', 'mmmmmmmmm', 'crisp delicious extreme price hike', 'rice', 'good product especially gluten dairy free friends', 'unavailable', 'eat one', 'best ever', 'lemonylicious', 'easy summer dessert', 'graham crackers good enough mommy eat', 'organic honey grahams', 'organic graham crackers', 'taste smell intolerable', 'great taste', 'great snack', 'great healthy snack', 'perfect little toddler hands', 'baby toddler love', 'well', 'daughter first word cracker', 'favorite', 'ever wants eat', 'yummy clean', 'great', 'little ones like no soy', 'plastic food', 'earth best rice lentil dinner', 'baby lilly says thumbs', 'good flavor runny though', 'dessert nutritional enough', 'baby favorite dinner', 'organic tasty', 'baby likes one', 'baby liked', 'moms dads beware plastic food', 'baby favorite stage food far great constipation', 'garbanzo beans give horrible gas', 'baby loves plastic', 'sons favorite dinner', 'baby not like', 'great place start', 'baby likes', 'one favorites', 'yum', 'jarred baby food son ate', 'calories yumminess', 'organic tasty', 'toss jars', 'great', 'son favorite dish', 'son loves', 'one son favorites', 'no issues', 'make best baby food', 'favorite', 'geat product', 'found shredded plastic baby food', 'love', 'son loves', 'great stuff', 'great taste picky baby thin compared others', 'runny odd tasting', 'favorite', 'good not best flavor', 'baby favorite dinner', 'daughter favorite jarred food', 'good', 'mustard lover', 'beaver brand honey n mustard mayonnaise sauce', 'great', 'eco sugar', 'inside corroded', 'not safe', 'tastes like mushy pineapple', 'rotten spoiled taste look', 'great option keeping fruit work', 'great dessert', 'best canned fruit ever eatten', 'close original hard candy', 'outstanding werithers candy', 'mmmmmmm sooo good', 'caution addictive candy lt', 'amedei', 'da vinci sugar free blueberry syrup', 'good', 'zesty spearmint lemon modulated green tea substantial potion', 'cookie chips not tasty', 'oreo dipped delight bars', 'yummy', 'seemingly impossible', 'yummy', 'chocolate wafers identity crisis oreos deception helps monitor calories not', 'yummy', 'oreo thin crisps work', 'oreo thin crisps calorie packs', 'good snacks', 'true mainstream diet snacks', 'yummers', 'calorie cakesters', 'not bad', 'fantastic little treats', 'calorie pack chips ahoy cookies', 'great calorie treat', 'good enough satisfy', 'good snack', 'teaching cookies', 'delicious', 'not best cookies ever', 'good product not fresh', 'ai not oreo', 'good serious', 'agree p lucas', 'delicious mini chocolate treats help weight loss efforts', 'crispy crunchy chocolatey', 'oreo flavored crackers without creme filling', 'fan', 'yummy cookies', 'oreo crisps', 'chocolate wafers identity crisis oreos deception helps monitor calories not', 'good buy', 'portable edible oreo', 'good snack', 'ok', 'great taste', 'good', 'flavor calories fat nearly', 'oreo transformed baked chocolate wafer snack', 'peanut butter cookies', 'amazingly good', 'hard find stores', 'best oyster soup', 'yum', 'beautiful delicious', 'superb pasta', 'great product', 'crispy thin delicious', 'ultra thin wasa', 'oh boy crispy calories', 'kavli crackers important part diet', 'want thinnest crispbread', 'best cracker earth', 'kavli bread', 'paper thin crispy good', 'crispy versatile delicious', 'mmmm crunchy', 'best cracker ever', 'another great snack', 'helps digestion', 'crackers', 'super tasty happens healthy', 'nice', 'nice thin', 'love thin wafers', 'great low calorie dieters', 'danger', 'kavli', 'wheat free alternative', 'really good muffins', 'wonderful blend millet garbanzo brown rice flour', 'poor food design', 'not expected', 'love pancakes', 'could not stop gagging', 'bitter disappointment', 'break allergy baking scratch', 'good mix', 'good gluten free', 'many mixed reviews', 'nasty', 'great muffins', 'simply nasty', 'probably would better make something like scratch', 'good store bought mix', 'yummy', 'bitter pill', 'oh bitter tasting', 'needs additions', 'healtier not guilt free', 'hodgson mill brownie mix', 'guilt free yummmmm', 'surprised good reviews', 'delicious brownie', 'higher fiber yet tasty especially add mini chips', 'best brownies', 'good healthy dessert needs work', 'feel better brownie health', 'oily gritty finished product', 'good like flax seed', 'grrrrrrrreat', 'yummy', 'love em', 'good back basics bread', 'great glorious super wonderful delicious bread', 'yummmyyyy', 'excellent bread machine mix', 'potato bread', 'like gummy white bread', 'fave hodgson mill bread mix', 'awsome bread', 'potato bread winner', 'nice bread', 'hodgson potato bread', 'great product', 'good use bread machine', 'excellent bread mix', 'great easy homemade bread', 'great bread', 'hodgson mill bread mix products', 'improved easily', 'potato bread', 'excellent bread mix', 'good', 'great bread', 'always great brand full line products choose', 'delicious homemade bread', 'perfect delivery system', 'suzie puffed thin cakes', 'best gluten free substitute bread worth every penny', 'better expected', 'words fail describe much love', 'much inorganic arsenic', 'best snack', 'loved shared everyone loved', 'delicious low calorie healthy snack good price', 'best rice cake ever', 'great sandwiches', 'great little rice patties', 'best value', 'excellent healthy', 'surprisingly tasty', 'great light cracker substitute', 'like em', 'great value cost', 'ener g foods english muffins', 'ener g english muffins', 'gluten free english muffins', 'good slightly expensive', 'gluten free english muffins', 'ener g english muffins amazon', 'mushy english muffins', 'pretty good considering', 'choice bread', 'not like regular english muffins', 'english muffins', 'ca not keep fallin apart', 'english muffins', 'jeremiah pick great coffee', 'coffee beans', 'dried mega bone', 'dingo bones best', 'yum yum', 'mild sausages', 'love smokies', 'yum', 'good not looking', 'buffalo bills smokies', 'ole smokies', 'really good', 'honey beef sticks saddlebag packaging', 'great flavor', 'pretty darn good', 'teriyaki ole smokies beef sticks', 'good unique', 'better thought would', 'good jerky', 'sweet beef', 'best yet found', 'mild slim jim', 'popular not', 'taste great', 'good beef sticks', 'great strong coffee lovers simply best coffee', 'best coffee', 'finest around opinion', 'great coffee great price', 'smotth never bitter even made extra strong', 'best dark roast coffee ever drink', 'good gourmet', 'not best', 'best', 'yuban dark roast coffee', 'great product', 'woeber sandwich pal hot spicy mustard', 'woeber makes great product', 'good snacking item', 'poor choice', 'great low carb replacement salt vinegar potato chips', 'things really good', 'good', 'salt vinegar pork rinds', 'tasty', 'needs salsa chips taste good', 'timely delivery', 'plocky tortilla chips red beans n rice', 'spicy', 'delicious', 'organic yummy chips ask', 'different flavor', 'best widely available bbq chips', 'favorite chips kettle', 'amazing taste best chip ever', 'simply best', 'addicted', 'really good chips', 'perfect tortilla chip goodness', 'plocky sweet smokey chipotle whole grain tortill', 'tasty beware', 'chips addictive', 'not favorite chip', 'black beans never tasted good', 'excellent tortilla chips', 'best chips ever', 'broken chips tasty', 'delicious chips', 'organic label misleading', 'tasty', 'meh', 'smokin', 'delicious additive', 'faboo dangerous prone chips binges', 'spice grow', 'best tortilla chips ever eaten', 'excellent chip', 'wrong flavor got country bbq instead chili chipotle', 'great', 'plocky rice beans tortilla chips', 'huge fan chips', 'plocky tortilla chips tasty healthy', 'plocky three grain tortilla chips', 'fanfreakintastic', 'tasty make sure gum', 'om nom nom nom', 'delicious healthy', 'yummy chips', 'unique schrumshist tasty tortilla chips', 'music palate', 'yummy', 'kettle organic chipotle potato chips', 'best kept secret', 'not stop carrying chips', 'best tortilla chips ever', 'hot good came back', 'go nuts ass kickin peanuts', 'excellent', 'stale rancid oil taste like even tiniest bit salt flavor chips', 'good', 'yowzah', 'unique flavor fans thai food', 'delicious crisp chip good flavor', 'best gluten free dairy free chips', 'best buy bbq chips', 'love', 'crunchy tasty', 'convenience low cost', 'wow', 'salty vinegary', 'delicious', 'quite good', 'tangy goodness', 'love chips thick crunchy', 'ridiculously good', 'kettle potato chips sweet onion', 'best chips ever', 'slight taste jalapeno', 'pretty good could better', 'best deal ever', 'glad find oz size', 'fresh lightly spiced crunchy kettle chips good value good product', 'kettle potato chips fully loaded baked potato', 'yum', 'hard', 'barbeque perfection', 'excellent thai flavored chip', 'delicious', 'pucker', 'disgusting', 'supreme salt vinegar', 'used favorite chips', 'great deal', 'kettle chips', 'chips awesome not best', 'made mistake', 'love smaller bags', 'tasty', 'best chips ever tasted', 'best chip', 'tangy delicious snack', 'best kettle chips', 'stars price taste', 'good', 'awful sometimes awful', 'expired stock', 'kettle foods spicy thai chips', 'delicious', 'awesome chips', 'chips tasted good', 'best chips', 'yummy tummy', 'great strong flavor', 'crunch wow', 'chip kiss salt', 'caution kettle chips addictive', 'yummy', 'potato chips yummy', 'stale beware buying special', 'c h p c h p h r b c k r b r b e c u e', 'completely ripped', 'delicious yet companions wont touch', 'love kettle chips not flavor', 'maybe worst chips ever', 'surprise different', 'tasty', 'crisp', 'spicy thai chips', 'delicious else expect', 'great value', 'better jalapeno kettle chips', 'spicy good', 'potato chips', 'lightly salted heavily delicious', 'love first bite tongue puckering tang crunch', 'best chips period', 'delicious extra crunchy', 'chip snob alert', 'best salt vinegar', 'gourmet powerful salt vinegar chips', 'changed chips taste horrible', 'not miss salt', 'great deal', 'best chips', 'great price not tangy expected', 'kettle chips', 'absotively posilutely delicious', 'gone hill', 'lightly salted yet tasty', 'best unsalted chips', 'delicious', 'defacto standard salt vinegar chips', 'awesome delicious', 'great chip', 'much flavor farts smell like sweet onions', 'favorite flavor', 'kettle brand potato chips new york cheddar', 'favorite kettle flavor great value', 'horrible cant believe', 'great hot new flavor', 'tang packs punch', 'orgasmic', 'kettle chips make great mouse food', 'bags damaged holes stains', 'thing ever addicted chips', 'kettle sold chips horrible', 'awful taste', 'sour', 'not madhouse munchies', 'garbage', 'chips', 'bags salt chips added', 'not good', 'dripping oil', 'disappointed', 'no salt kettle chips', 'fried', 'taste terrible way strong', 'delicious', 'one bite become chippoisseur', 'good chips', 'happened recipe changed', 'best chips anywhere', 'one bite become chippoisseur', 'one bite become chippoisseur', 'sweet salty tangy way snack', 'fantastic', 'like spice get', 'chips make fat', 'eating years', 'buy eat happy', 'great tasting chips', 'kettle chips sea salt', 'great tasting chips', 'pretty tasty decently spiced', 'crunchy spicy', 'amazing service', 'best salt vinegar chips', 'favorite kettle chip', 'smiles', 'spicy thai', 'kettle chips', 'great chips low sodium', 'burns skin lips', 'awesome', 'good chips', 'yoli', 'good buy', 'yum want snack something really good', 'yummy', 'love kettle chips', 'crispy crunchy robust', 'like', 'highly addicitive chips', 'great chip', 'crunchy salty sweet finally superbowl snack scooores', 'chips make weak knees', 'far favorite chips', 'good chips cheese', 'habit forming', 'not creamy chivey', 'firm quality chip', 'not bad little hard get used', 'great chips', 'chips bag cooked', 'good chips great price', 'yum', 'pretty good tasting chip', 'yummy chips', 'best sour cream onion chip', 'great chips', 'fabulous', 'box chips', 'fantastic not beat taste not resist one spice lover', 'addictive potato chip', 'love chips', 'one best flavors', 'awesome', 'good tangy', 'delicious', 'salt vinegar chips', 'excellent chip', 'delicious always', 'oooh yummy', 'not quite best', 'want gaain twenty pounds no control whatsoever buy', 'best', 'indulgence bite', 'best chip ever', 'tangy spicy sweet oh', 'excellent balance taste crunchiness moisture', 'best chips ever', 'not even like kettle chips love', 'love sea salt vinegar already', 'addictive', 'amazing chips', 'tastes ok bits shells', 'pretty good', 'ugh', 'wonderful', 'delicious low cal treat', 'awesome fresh tasting lobster soup perfect heat serve', 'watery', 'disgusting nasty inedible', 'far canned soups go', 'baxter canned soups rule', 'bad tasting soup', 'wonderful loose leaf tea', 'excellent casablanca tea', 'little sweet', 'really tasty', 'awesome', 'truffle oil well least oil real', 'yummers', 'keeps dentest chair', 'love dressing wild thymes products meyer lemon dressing', 'felt like thief bought', 'india tree superb', 'looking', 'best bad breath no fowl taste', 'orbit white peppermint best', 'southwest oldie', 'delicious organic orzo', 'applesauce spice cake', 'really gluten free', 'rotel saves daily basis', 'fabulous not amazon', 'yes good', 'best green tea', 'hard find better', 'taste n aw ins great spice mix many dishes', 'great cajun seasoning', 'wonderful product', 'good everything', 'luzianne seasoning whoo hoo da best', 'great seasoning', 'best kept secret not really', 'miss south', 'excellent mix spices love', 'luzianne awesome', 'love seasoning', 'dissappointed never buy', 'msg garbage', 'excellent wish safeway still carried', 'fantastic catfish', 'great stuff', 'looks better tasted told', 'healthy surprise', 'wonderful', 'boys love', 'tasty not sweet', 'great nutritious', 'eat fig bar instead', 'not terribly appealing', 'best cereal bars planet', 'yummy', 'cost increased size decreased', 'not fan', 'highly recomended', 'berry snack bars', 'small good', 'child loves', 'great snack', 'great bars gluten free diets', 'absolutely vile', 'pretty good overall', 'perfect size', 'yummy small', 'not go wrong', 'great taste size smaller', 'good berry flavor', 'something changed', 'chocolate ones much better', 'good berry flavor excellent price', 'really wanted like', 'cheaper ingredients lowered quality', 'taste great good', 'canned mackeral', 'yum', 'mackerel', 'great', 'pretty good', 'tasty lunch snack', 'season mackerels', 'not happy product', 'fantastic product', 'love fresh food feeder', 'great teething', 'absolutely love', 'great eating whole foods clean veggie brush', 'love love love', 'delicious', 'good seasoning', 'perfect salad dressing', 'best simpliest salad seasoning', 'best salad seasoning ever made', 'candy tree organic cherry bites', 'gluten free bliss', 'gluten free licorice', 'better cherry nibs ones gluten', 'got chest cold nasty cough', 'great tasting', 'great treat snack', 'love twists', 'good', 'woderful wild rasberry french twists', 'knew great choice', 'not bad', 'simple good', 'tastes fresh', 'tasteless low calorie', 'tasty', 'right size taste', 'must spoiled', 'not like countries cadbury', 'different taste made uk made india version', 'low carb angel food puffs', 'clam chowder', 'tasteless', 'bar harbor news england clam chowder', 'perplexed', 'yes', 'opinion best clam chowder perfect winter meal', 'clam chowdah hog heaven', 'clam chowda pizza awesome simple make', 'lacks certain key ingredients', 'possibly best canned clam chowder available', 'nothing special', 'best', 'not good', 'simplicity best', 'buy', 'stuff', 'clam', 'rather chunky', 'best canned chowder', 'bar harbor natural new england clam chowder cans pack', 'bar harbor clam chowder', 'bar harbor clams', 'dropped plane', 'mmmmmm', 'good lots clams natural recipe', 'never arrived', 'great gag gift', 'yuck', 'excellent product', 'apple cinnamon muffins', 'no ingredient list', 'tasty', 'awesome rum cake', 'love', 'best gravy ever', 'pioneer brand peppered gravy mix', 'great tea', 'best tasting wheat free gluten free cake mix available', 'cake occassions', 'namaste foods gluten free vanilla cake mix', 'could better', 'awful', 'yummy cupcakes', 'tasty', 'awesome changes', 'strange flavor', 'birthday saviour', 'best organic green tea', 'refined tea taste', 'best organic green tea available teabags', 'sugar raw', 'lie', 'good product', 'excellent', 'great product weak packaging', 'awesome sugar', 'never use white sugar', 'sugar raw', 'good product terrible agricultural practices', 'sugar raw', 'great', 'excellent not perfect', 'sugar', 'medicinal tea really helps', 'healing tea', 'great tasting tea cold flu', 'lifesaver', 'good tea bad bag', 'kuhflecken chocolate bar', 'delight says', 'never got', 'best stuff ever', 'bigger amount smaller price supermarkets', 'satisfied', 'wonderful condiment', 'exotic pantry stuff pomegranate molasses', 'not use place regular molasses', 'love use many things including mother secret recipe', 'would recommend product', 'great find', 'dog really likes iams savory sauce', 'decent not great', 'great alternative cough drops', 'best', 'try ramen noodles', 'rat terriers love stuff', 'half empty cans greasy inconsistent ingredients', 'dozen stars', 'surprised layer fat top contents', 'grammy pot pie dogs dogs love', 'caution dented cans', 'please think twice', 'gets picky dog eating', 'grammy pot pie please', 'love grammy', 'dog love', 'great', 'waste money not buy', 'ground fennel seed', 'seasonings', 'cats love real food cat food', 'picky cat child loves', 'dad really liked', 'perfect sampler milka chocolate', 'great candy family loved', 'hot mustard', 'super mustard', 'hot', 'best mustard ever', 'ummm ummm good', 'thomy scharfer senf', 'thomy mustard maniac', 'make fresh fruit tart light beautiful', 'google name reports suspected poisoning made china', 'jerky strips', 'hot', 'hot delicious', 'thick creamy nice flavor', 'good dressing', 'instant favorite', 'good', 'good price good product', 'sorry taste not pleasing', 'great fat free ranch', 'wish bone fat free ranch dressing', 'delicious tea', 'ca not detect prickly pear', 'totally delicious delightful', 'yummy wonderful inexpensive gift item', 'excellent service', 'plenty fresh', 'excellent produce', 'exceptional', 'great combo flavors', 'yummy', 'extremely disappointed', 'piggie skins', 'wrong product displayed order', 'great treats', 'sheltie adores', 'pug loves got different hartz treat', 'one favorite places earth', 'false advertising terrible dog food', 'good ol dubble bubble taste', 'great gift', 'lazzaroni tin', 'great gift', 'lazzaroni amarettini cookies', 'wanted', 'misleading product want no bees use', 'must gardener', 'avoid like plague contains product killing honeybees', 'combo rose food systemic insecticide', 'excellent product', 'easy rose care great product', 'great product', 'good tasten tea', 'hard find tea', 'better taste expected', 'lovely', 'sassafras tea bags', 'sassafrass tea', 'sass tea', 'awful taste', 'k', 'no caf no taste either', 'great value', 'lovely tea', 'hope got bad batch', 'real rose petals delicious flavor', 'eliminate natural flavor additive', 'pleased', 'not rosey', 'perfect', 'davidson rose congou leaf tea', 'rosematic', 'no pepsi', 'look elsewhere whole grains', 'product great price line', 'great flavor jell', 'jell', 'makes great skinny margarita', 'taste tested wine maker', 'cough medicine', 'beefeaters swizzles tripe inch pack', 'not pieces', 'not traditional caramel lovers', 'candy', 'great caramels', 'caramel fantastic', 'porcini mushrooms excellent product', 'excellent flavor mostly large pieces', 'excellent product', 'delicious', 'love tea taste buds', 'horrid', 'could give rating one star', 'tasty good value', 'packed wrong oil', 'not really low sodium lot salt', 'low sodium still enjoying kosher food', 'mild firm inexpensive', 'sardines', 'perfect diet aid', 'best', 'like', 'satisifed customer', 'roland sardines healthy good', 'good products low sodium diets available amazon', 'good sardine choice', 'best', 'excellent sardines', 'water low sodium sardines actually taste good', 'great taste low sodium', 'healthy tasty convenient not expensive', 'excellent item excellent price', 'amazon sardines good low sodium dieters', 'like buttah', 'pocky sticks together', 'good stuff', 'great buy', 'pocky', 'not taste', 'yummy', 'fun popping crispy sticks dipped chocolate special treat manga fans find local wait till fall', 'great product', 'great tasting snack get japanese pocky', 'item awesome', 'love snack', 'delicious', 'happy pocky sticks', 'awsome', 'great', 'yummy', 'shipping charges excessive', 'diabetic delight', 'yummy smooth delicious', 'fast delivery item described', 'great diabetic friendly candy highly recommended', 'great', 'bread mixes', 'makes nasty loose poo', 'ferret loves', 'high quality gave dog wicked gas', 'eukanuba puppy small breed dog food', 'heaven earth', 'yummy dulce de leche', 'yummy milk spread', 'exactly like argentina', 'almost good homemade', 'heavenly', 'excellent', 'love dulce de leche', 'dulce de leche', 'yummy treats', 'dogs love em', 'dog loves liver biscotti', 'make dog happy', 'great treats', 'excellent dog treats', 'jack treats', 'great treat way overpriced shipping charges', 'dogs go crazy', 'rich j wyzykoski', 'waste money', 'liver biscotti rules house', 'bulldogs rule', 'healthy non fattening right size delicious', 'great training', 'best friend treats', 'good training treat', 'dogs love treat', 'great product', 'woofs', 'best dog treat ever', 'lucy treats', 'great licorice flavor', 'excellent tasty chewy', 'natural licorice ca not beat', 'real licorice', 'best', 'awesome people love die hard licorice fans love', 'jonesing panda', 'best black licorice', 'real licorice', 'panda licorice', 'delicious licorice', 'love licorice', 'delicious', 'licorice lowers blood sugars', 'soft right amout flavor', 'awesome licorice', 'love licorice', 'taste like', 'not leave teeth black', 'mmmmmmmm', 'good nature licorice', 'panda natural soft licorice', 'likes', 'panda boxes little licorice pieces', 'best licorice', 'decent licorice', 'great taste medicinal value', 'panda licorice', 'good traditional licorice', 'favorite natural licorice', 'licorice', 'close perfect', 'great natural snack', 'licorice lover', 'panda licorice', 'nice condiment', 'great product', 'sea salt', 'great taste less sodium', 'cuttiest gum century', 'flavor gods', 'awesome tea', 'best tea', 'pg tips bags', 'not love pg tips', 'great product', 'great tea', 'stale', 'cracker jacks stale', 'love cracker jacks hate amazon', 'no stale product', 'awesome packaged promised', 'cracker jack', 'great item', 'like good ol days', 'stale', 'perfect', 'cracker jacks', 'ummmm cookies', 'much better gluten dairy free cookies', 'chocolate chip potato cookies', 'great cookie ideas', 'good cookie', 'tasty cookies', 'potato cookies', 'yummy', 'good', 'best licorice jelly beans ever', 'fantastic', 'delicious black jelly beans', 'excellent authentic chinese dishes', 'one favorite cookies', 'pathetic cookie compared tang', 'favorite grocery store chocolate chip cookie', 'not eat cookies bed', 'gross cookies', 'reviewing mistakes cookies', 'stick keebler elves', 'bad flavor combination', 'new amazon com sells biscuit crumbs', 'great price', 'arrived fresh good shape', 'delicious though bit small side', 'mini cookies mini merits', 'no brainer', 'great school lunches', 'yummy indulgent tasting cookie', 'ehkkkkkkkkkkkkkkk', 'good store bought cookies', 'great snack', 'great baby shower party favor', 'much better milk chocolate', 'great dipping chocolate right microwave', 'best tea ever', 'excellent nutrition', 'perfect sporting dog', 'omg life saver', 'no shedding', 'dog food', 'best food best friend', 'great food', 'happy danes', 'worth', 'packaged red wheat seeds', 'good way expensive', 'love tea', 'wonderful', 'best winter tea party', 'fun intense holiday tea', 'sweet dreams', 'large quanity discontinued seasonal delicious tea', 'fast shipping good company buy', 'good true', 'pretty good pickles', 'seven days bad taste mouth', 'bacon supposed', 'best part early summer', 'perfect', 'easy grow good cat', 'dead seeds', 'easy grow cats love', 'good stuff', 'great value', 'kitty grass', 'love', 'cat loves', 'great product', 'cat grass', 'ignored', 'cats love', 'great seeds', 'cat grass', 'easy grow', 'oat grass grows well', 'cats love stuff', 'cat grass', 'tiger loves cat grass', 'enjoyed', 'cats love', 'grow easy', 'cats love taste love price', 'great cat grass seeds', 'cat grass', 'good grass', 'excellent growth', 'cat grass no longer cats', 'grow grass man', 'great stuff grows fast full', 'great product service', 'daily serving greens cat', 'great grass', 'meeeeeeowwwwwww', 'easy grow cats love', 'cat grass grow real cats', 'best canned tomatoes', 'margherita pizza', 'best sauce tomato canned fresh period', 'dog thrives', 'doggy prison food', 'no worries good stuff', 'horrible', 'not fooled', 'something organic pesticide', 'chicken meal', 'not organinc dont fooled organics name', 'grains not belong dog food', 'great dog food', 'deceptive disappointed', 'newman organics dog food', 'give time', 'newman organics dog food', 'organic dog food', 'something changed quality control must slipped far organic goes', 'laser light show awesomness dog', 'dogs like love amazon carries', 'bad batch made dog sick', 'newmans', 'top paws dog', 'newman review', 'good even dog not turn nose', 'doggie loves lot budget not much', 'great dog food', 'blows away store bought', 'newman dog food best', 'far good', 'dog loves', 'not sick anymore', 'dogs special needs', 'see positive difference dog quality life', 'dog needed', 'dog loves', 'best dog food ever', 'best dog food ever', 'nice organic cage free option sensitive stomach', 'best dog food', 'good stuff', 'dog liked wanted variety', 'excellant product', 'quality organic ethical dog food', 'scared sophia terrible diarhea', 'dog loves food like convenience', 'best', 'paul newman saved dog', 'good product', 'great dog food dogs digestive problems', 'great product no hormones antibiotics meat', 'premium dog food', 'helped dog skin issues', 'food working shockingly well allergy prone pug', 'best organic food feed fur babie', 'allays concerns feed first baby', 'newman organics dog food', 'dog loves', 'awesome product', 'quality pet food', 'subscribe save option good deal', 'newman organics adult dog food formula bag', 'non existent customer service', 'yummy even finicky dog', 'love newman products', 'great product need adjust subscription', 'great option organic dog food', 'love newmans adult dog food', 'good not favorite', 'newman organics advanced dog formula active senior dogs bag', 'best dog food ever', 'great product', 'shiba inu loves', 'like newmans', 'great product', 'dog favorite', 'first rate dog food', 'finiky digestion', 'awesome awesome dry food dog without worry', 'terrifc', 'great healthy dog food', 'great dog food', 'newman organic dog food', 'dog loves', 'great dog food', 'great little guy huge difference store brand', 'picky dog loves stuff', 'dog loves food', 'happy', 'happy dog', 'great picky sensitive dogs', 'best dog food', 'dog loves food', 'dogs love', 'satisfactory', 'dogs love', 'fussy dogs eat', 'one best year old jack russell mix', 'dogfood', 'dogs never throw', 'good quality', 'great alternative', 'love', 'good natural dog food', 'dog loves', 'good dog food', 'best price around great dog food', 'great product dogs love', 'organic dog food', 'dog loves', 'love anything newman', 'not organic', 'great dog food', 'great dogs allergies', 'newman organic dog food', 'organic dog food', 'agree previous reviewer name deceptive', 'best dog food market', 'wish dog liked', 'picky dog loves', 'dog loves food', 'dogs refused eat', 'great food', 'not thought', 'one', 'good stuff', 'newmans organic dog food', 'great dog food min pin lb dog', 'deceitful brand name', 'healthier', 'not good enough', 'healthy food dogs love', 'dependable top line product', 'apparently delicious healthy', 'newman organic dog food', 'dog not like', 'great dogs', 'gma pat', 'great product great cause', 'still best', 'tell great', 'fine product', 'excellent dog food', 'dogs scarf', 'great miniature schnauzer', 'dachshunds love', 'newman organic dog formula', 'dog loves', 'not purchase', 'great food', 'dog seems enjoy', 'great dog food', 'good stuff', 'really gross', 'good worst tasting tea eeevvveeerrr', 'go coffee subsitute', 'apparently good tastes like bitter dirt', 'love', 'cup dandelion tea day keeps doctor away', 'great tea', 'excellent item service', 'nasty', 'use every day', 'great tea', 'perfect treat', 'best sweets', 'another favorite', 'good flour gluten free baking', 'great gf baking', 'great football fans everything', 'yummy', 'great service delicious candy', 'best bean', 'disappointed', 'chiclets fond memories taste past fresh new', 'say chiclets', 'delicious tea great aftertaste', 'love', 'delicious tea', 'amazing tea favorite', 'amazing worth every penny', 'delicious tea', 'great spicy taste hint sweet', 'favorite tea', 'mmmmmmmmmm', 'beautiful experience', 'excellent tea', 'excellent', 'totally delicious', 'great health benefits', 'terrible', 'love', 'ginger fans', 'stash green tea powder', 'good tea', 'great go makes water little less boring', 'beware corn allergy', 'tea', 'great product', 'great tasting easy use', 'perfect summer tea', 'mint tea bought', 'refreshing flavor', 'not taste', 'al stash iced teas best still not good', 'way weak tastes', 'awful', 'great tea', 'great product', 'quality lightly sweetened green tea powder', 'not sweet not strong right', 'great pick go hot cold', 'good stuff', 'wonderfully refreshing drink', 'easy tasty better health', 'refreshing', 'love', 'first time purchaser', 'lightly sweetened green iced tea powder', 'stash tea powder review', 'mona lisa', 'not much', 'good go', 'good tea taste not sweet', 'tastes great', 'way weak tastes', 'mild taste easy mix buy', 'got diet soda', 'nice green iced tea beverage', 'ice tea', 'pretty good stuff right sweetener', 'yum yum yum', 'mom', 'best instant green tea ever', 'not', 'not worth', 'would not bother', 'powdered tea', 'not bother', 'no flavor not authentic', 'powdered green tea stash', 'experience', 'stash premium mint green iced tea powder', 'convienent', 'reasonably priced delicious', 'stash instant green tea', 'flavorful refreshing', 'nice substitute soda sugary tea', 'great alternative bottled green tea', 'crushed leaves', 'lightly sweet cheeper jamba juice matcha shot', 'great product last', 'waste money', 'refreshing summer beverage', 'great taste convenient', 'refreshing addition water', 'finally affordable delicious green tea powder', 'expected', 'best wafers', 'works hard open buy larger version instead pod', 'found solution open', 'works saves', 'thing great', 'great concept poor product', 'small hard open', 'not open', 'great idea pain open close', 'save money', 'keeps basil counter cat proof', 'works great', 'wilted hopes', 'works', 'wonderful perfect saves fortune', 'stylish saver', 'caveat emptor disappointing', 'gadget not job', 'sorry oprah not one favorite things', 'picture misleading', 'buying', 'healthy dog food', 'scrumptious', 'skimpy price charged shocked', 'love salsa', 'sweet nice kick', 'broken bottle bottoms', 'deceptive photo', 'awesome candy', 'great stuff', 'naturally delicious', 'word warning love tea', 'best tea earth', 'mentos', 'cinnamon good', 'good product', 'like tiny light flavored peanut halves', 'perfect espresso', 'worth cost due unique flavor favorite sugar', 'best brown sugar cubes', 'extraordinary', 'another good soup hc', 'outstanding soup sensation', 'thick sweet heavy tomato base not mexican spiced', 'good product better price elsewhere', 'yuk', 'great color', 'yummy', 'glad', 'toffifay', 'om nom nom', 'good buy', 'cute item expired', 'disappointment', 'rudolph gingerbread house', 'not one twice came broken', 'not easy looks', 'spongetastic', 'sons loved making easy enough adult supervision age neat project', 'fun paint', 'hippy eucharist', 'great', 'best healthy cookie ever tasted pretty sweet', 'good not great', 'chewy satisfying', 'great cookies terrible price', 'best bean ever', 'great food', 'great dogs allergies', 'bad', 'perfect english bulldog allergies', 'great allergy sensitive dog food dogs love', 'great dog food', 'good healthy dog food', 'convenient', 'mmmmm mmmmm good', 'great dog food', 'great food dog sensitive stomach', 'great food', 'better life dog', 'great stomach problems', 'great dog food', 'really nice flavor', 'overpriced', 'delicious strong japanese black coffee candy', 'intense', 'lots pops', 'dum dums', 'formulas excellent dogs', 'cat likes', 'passed taste test', 'dogs love', 'fussy min dachshund loves taste', 'dog sheds less', 'not well dog', 'quality dog food delivered door', 'awesome', 'would give harmony farms extra stars could', 'great dog food', 'high quality dog enjoys budget', 'dogs love', 'good', 'ten year old doxie', 'harmony farms review', 'hard find locally', 'good product', 'dog loves dog food', 'no good', 'solved different digestive issues different dogs', 'best food dogs', 'great dog food', 'delighted amazon com', 'dog likes great value', 'great dog food', 'great dog food', 'fabulous food', 'good dog food', 'excellent wheaten terrier sensitive tummies', 'woof woof', 'good stuff', 'dogs love', 'excellent taste', 'excellent g f', 'amazing', 'tasty chips', 'yummy', 'priced chips lack rice taste', 'best', 'no habla espanol', 'energy shots works', 'not make cut', 'blecch', 'deadly product', 'wow rocket fuel humans', 'good things come small packages', 'great substitute energy', 'good quality dog food', 'tasty quick meal', 'fan', 'not good', 'chicken rice', 'not lot flavor not lot chicken', 'hormel compleats simply wonderful', 'stonewall pancake mix', 'great backup scratch', 'love stonewall kitchen', 'great waffle every time', 'perfect waffles', 'deeeeelicious', 'delicious waffles minutes', 'great belgian waffle batter', 'stonewall pancake waffle mix', 'farmhouse waffle mix', 'favorite breakfast choice', 'excellent', 'excellent choice belgian waffles', 'great waffle mix', 'favorite', 'pancake mix best', 'stonewall kitchen pancake mix', 'believer', 'maybe batch', 'pretty darn good increased cost', 'great stuff', 'best waffle mix life', 'stonewall kitchen pancake waffle mix grrrrrreat', 'delicious pricey', 'great waffles us non cooks', 'excellent fluffy pancakes', 'good basic mix', 'best pancakes ever', 'good pancakes lots work', 'awesome', 'great tasting pancake mix', 'delicious waffles', 'great taste great price', 'disappointed first farmhouse pancake', 'great tasting pancakes waffles', 'best pancakes life', 'waffles schmaffles', 'best belgian waffles no time', 'tasty mixture', 'delicious easy', 'addicted', 'best breakfast', 'tasty pancakes little flat', 'family breakfast grand kids kids us', 'crispy soft', 'wonders one popularity kitchen', 'love', 'stars could yuk yuk yuk', 'best pancakes ever', 'best waffles', 'delicious makes great gift', 'processed taste', 'delicious yummy', 'not sure hype', 'favorite pancake mix', 'not buy best', 'confused', 'price versus taste not add', 'good not great', 'not impressed', 'tasty pancakes best mix ever tried', 'best waffle mix ever', 'scrumptious', 'best', 'great stuff', 'best', 'yum', 'yummmmmmmmmm', 'pancake waffle mix', 'yummy yummy yummy', 'best waffle mix', 'not sweet mixes', 'hands best pancakes ever', 'best ever', 'really good expensive', 'banana recipe', 'perfect weekend', 'tasty texture great', 'best waffle mix find', 'awesome cereal', 'kellogg mueslix', 'great cereal', 'good bring back right cereal', 'love love love mueslix', 'nothing like actual muesli', 'contains trans fat high fructose corn syrup', 'superior hard find product', 'cereal', 'favorite cereal', 'love mueslix', 'ideal breakfast', 'best cereal ever eaten', 'wonderful breakfast snacks', 'great taste healthy cereal', 'hard find cereal found', 'finally', 'mom favorite ceral', 'yummy ur tummy', 'not grocery stores', 'great mix fruit nuts whole grain', 'mueslix cereal', 'buyer beware product contains high fructose corn syrup', 'love', 'overall', 'kelloggs muselix great', 'kellogg mueslix cereal', 'tastes different much worse', 'floral tasting tea', 'tea', 'not light not sweet oh wonderful flavor', 'revolution tea', 'disapointed', 'best tea', 'revolution teas smooth delicate', 'makes great iced tea', 'delisious pancakes', 'great around mix', 'great mix', 'perfect mix egg allergic', 'awful', 'poor item packaging', 'good egg allergy', 'arrowhead mills whole grain buttermilk pancakes easy', 'non alcoholic', 'tastes great', 'bland', 'yummy', 'great organic tea great price', 'great deal great tea', 'nice flavorful tea purist black tea addict', 'best tea', 'great tea', 'fine tasting full lea great value', 'best breakfast tea ever', 'delicious consistently good quality', 'beautiful presentation pretty good tea', 'break easily', 'wonderful tea', 'satisfying', 'oatmeal oatmeal lovers', 'best instant oatmeals', 'good instant', 'great irish oatmeal hurry', 'not like', 'good next time not order variety pack', 'good', 'great taste convenience', 'good hot breakfast', 'food great', 'love gluten free oatmeal', 'would not buy oatmeal mcanns tastes great', 'wife favorite breakfast', 'good way start day', 'oatmeal', 'stale product', 'not good quality', 'amazon please offer ladies brand rice paper', 'happened', 'great wrappers terrific bulk price', 'great quality', 'no heat', 'love sauce', 'uh no', 'tasty', 'great service', 'maybe not authentic yummy', 'dont waste money', 'not authentic', 'sauce kick no onions', 'yum', 'great tasting green tea great deal', 'best ahmad tea', 'fragrant tea', 'not real tea', 'nice tea', 'ahmad loose imperial blend tea great price', 'favorite tea', 'best tea ever', 'excellent loose tea', 'disappointed', 'get store', 'ahmad tea', 'good anytime hot tea', 'everyday cup tea', 'decent light roast organic', 'rotton upon receipt', 'peanut brittle', 'terrible', 'poor service', 'not buy', 'christmas shopping', 'yum', 'disappointing', 'worst caviar ever', 'wow great deal love love love', 'another great experience amazon', 'great red caviar tasty attractive eggs', 'great inexpensive caviar', 'hail israelis', 'great price quality caviar', 'yuck', 'much red dye little taste great lol', 'worthy every', 'bavarian creme flavor oil', 'not taste bottle mix vanilla true flavor', 'tao tea not get', 'delicious', 'great tea price', 'best earl grey ever', 'great well balanced earl grey', 'favorite earl grey tea', 'no tea flavor', 'nothing special', 'tasty tea', 'tasty', 'good coffee', 'excellent coffee', 'convenient', 'expensive online', 'no pot fresh coffee', 'simple convenient', 'brews excellent cup coffee quickly easily', 'convenient far better instant coffee', 'delish', 'great taste', 'excellent', 'much better tea bags', 'valentine gift winner', 'fresh tasty', 'good money', 'fresh whole perfect', 'not highest quality good price', 'best tea ever', 'order', 'delicious', 'soooooo good', 'new favorite', 'nice tea strong cranberry flavor', 'delicious', 'delicious cup tea', 'simply great', 'broke several uses', 'new inexpensive fix priced xlr usb mic interfaces', 'bllue mic icicle', 'came damaged', 'excellent preamp price', 'another great product', 'great little extra power source condensor', 'blue icicle not work windows', 'great product', 'windows users pay attention', 'worked', 'icicle mac os x', 'not work windows', 'works great no noticeable noise high output gain smooth flat responce', 'windows usb issue', 'cheap reliable solution', 'not working', 'not good cheaply made mxl micmate far superior', 'slight quality control issue', 'no good wii', 'transportable buen sonido', 'leave one shelf', 'worked hours stopped', 'feels like small lightsaber', 'excellent buy', 'works great', 'cost effective solution low budget home recording', 'good', 'worked great', 'awesome buy sure', 'perfect', 'job well', 'blue icicle decent', 'cold ice', 'works well need mono', 'works', 'needed', 'used audience mic pickup', 'almost five', 'awesome affordable worth', 'works perfect', 'stopped working', 'great product beautiful sound', 'pretty good money', 'awesome product', 'not deliver enough volume', 'true plug n play go wherever theres pc', 'not compatible windows', 'works well', 'works awesome', 'poor volume shure', 'noisy', 'cool stuff', 'business', 'cheap', 'not long term use', 'works great', 'match mic carefully', 'cheap', 'owned year windows problem', 'works perfectly sounds great', 'love', 'simple plug play worked period', 'stopped working okay', 'could better works inexpensive', 'good', 'quick easy durable touchy', 'little beast', 'afforable low noise xlr usb preamp', 'works great', 'works not enough gain', 'way better thought', 'icicle hot', 'great product unbeatable price', 'value money', 'great value way use nice rode mic', 'decent price good product', 'promising works not always guaranteed solution', 'clean sound easy setup', 'candy', 'great candy', 'great quality convenient quick cooking', 'best quick cook wild rice', 'quick wild rice ok', 'delicious best custard ever', 'wonderful product', 'hard find bird custard powder', 'bird custard powder', 'happily home', 'bird custard powder', 'best vanilla custard ever', 'true classic custard authentic yummy english trifle', 'barb', 'perfect size', 'spam meal', 'great deal convenient', 'beer nuts', 'salty hint sweetness', 'not best experience', 'flavor gone', 'happened', 'best', 'beer nuts', 'hard find beer nuts', 'great customer service', 'mild sweet salty blend', 'remembered', 'jgk likes beer nuts', 'u talked mr beer nut', 'mmmmmmmm beer nuts', 'msg ham base', 'ham base', 'oyster sauce', 'excellent taste', 'spicy mustard', 'great mustard', 'little mint', 'yum', 'absolutely wonderful', 'great feed others', 'sugar bomb', 'candies delightful', 'great', 'best cashews', 'nutty', 'best nuts ever', 'parmesan heaven', 'love', 'best sf white chocolate', 'delicious questions', 'yummy', 'crumbled cookies no fun eat', 'heavenly', 'nicely packaged serving', 'wonderful cookies', 'cookies crumbles', 'hands best mint ever', 'delicious', 'impossible find', 'best mint', 'bigger brands', 'great gummi', 'strawberry twizzlers yummy', 'always fresh', 'home delivered twizlers', 'great sweet candy', 'poor taste', 'twizzlers', 'please sell mexico', 'twizzlers strawberry', 'twizzlers', 'delicious product', 'love', 'nasty no flavor', 'great bargain price', 'fresh greasy', 'lots twizzlers expect', 'nice snack', 'good licorice', 'love', 'great kids', 'not worth', 'dirty martini', 'makes quick tasty martini', 'great dirty matinis', 'not really olive juice', 'dirty martini olive juice', 'much easier', 'olive juice', 'love', 'husband loves dirty martinis', 'good dirty martini', 'stuff', 'better real stuff', 'dirty martini olive juice', 'excellent service vendor', 'pleased product', 'tasty right amount salt fresh flavor', 'spectacular tomatoes', 'next best thing fresh tomatoes', 'ok', 'excellent tomatoes', 'olives melt mouth', 'no tuna false claim', 'organic simple fast', 'great chicken curry dishes', 'best curry around', 'easy indian cookingat home', 'delicate asian salad dressing', 'totally great balance flavors expect asian dressing', 'perhaps something wrong batch', 'drain', 'big disappointment', 'worst frosting ever', 'worst frosting ever', 'cherrybrook kitchen vanilla frosting', 'not buy frosting', 'taste neutral quantity deceitful', 'spectrum naturals walnut oil refined', 'lindt pistachio chocolate', 'delicious', 'ricore forever', 'best cinnamon gum', 'love gum', 'favorite sugarless flavor', 'amazing snack kids love', 'great toddler snack inconsistent quality', 'great toddler snacks', 'great little ones', 'love', 'great way get kids eat vegetables', 'got dog heart failure', 'crack toddlers', 'wonderful healthy snack baby', 'flavor texture not good batch', 'italy best pasta organic', 'tastes like home made', 'wow excellent', 'noticablely tastey', 'great product', 'fantastic healthy product', 'delicious tea slight hints almond chocolate not overpowering', 'garbonzo bean flour', 'yum falafel', 'perfect gluten free chocolate chip cookies', 'could say no blow pop', 'cherry could not find stores', 'great coffee', 'gevalia best', 'geliva coffee', 'favorite cofee', 'great way wake', 'coffee', 'love breakfast blend great gift', 'good coffee great service', 'right', 'best coffee outthere', 'wonderful smooth rich taste', 'delicious', 'best coffee', 'bit pricy really good', 'one best coffees ever', 'love coffee packs wallop morning', 'smooth brown wonderfulness', 'wow good espresso', 'best coffee', 'price keeps going', 'wow', 'one best coffees', 'dark smooth', 'not good', 'love', 'christmas canadies', 'user wrong', 'not kobe beef', 'perfect', 'swedish pearl not belgian pearl', 'excellent', 'nice sweet mango', 'not mango grape pineapple', 'anti oxidant smoothie', 'perversion taste', 'great taste', 'rich flavorful', 'nice strength maybe much vanilla', 'absolutely revolting', 'big pods great value delicious decaf coffee', 'disgusting', 'never go back senseo pods long available', 'aunt gussies highfat cookies', 'aunt gussie pecan meltaways', 'absolutely loved', 'good dessert someone gluten sensitive dairy sensitive diabetic', 'box stale crumbs', 'coffee pods', 'good bit big senseo', 'not good', 'great coffee', 'best home brewed coffee planet', 'good coffee', 'good flavor', 'norcal grandma', 'happened senseo decaf', 'melitta skip buzz', 'coffee pods', 'melitta one java pods', 'coffee', 'one java pods', 'not good', 'great alternative k cup users', 'weak coffee', 'best decaf coffee tried', 'smell', 'great tea', 'fantastic orange tea', 'great', 'good food good price', 'great dane loves', 'dogs love wallet love love', 'excellent healthy dry dog food', 'excellent food', 'best dog food price', 'fantastic dog food best price great quality', 'good food', 'quality good price', 'quality food less', 'quality good price', 'perfect great dane', 'superior product gmo free', 'not product received actual product may carry health risks comsumers', 'wasting vinegar cucumber shame', 'idea good diet food', 'asparagus bliss', 'best chips', 'delicious right amount', 'pop chip goodness', 'love chips', 'love product', 'love pop chips', 'definately stars deeelicious', 'everyone try least', 'popchips', 'treat', 'eat without feeling guilty', 'great tasting', 'amazing', 'salt vinegar bbq rock', 'watch addictive', 'def good buy', 'scrumptious', 'delish', 'chips', 'happy surprise', 'fully enjoyed', 'best healthy potato chip', 'luuuv popchips', 'good crunch light taste', 'pop chips great', 'good way try different flavors', 'yummy', 'great purchase', 'excellent', 'delicious', 'pop chips variety', 'great low cal snack', 'popchips r hella good', 'awesome', 'healthy yum', 'excellent', 'popchips perfect snack pop mouth', 'love', 'crunch without guilt', 'great taste calorie bag', 'love product', 'weird flavors', 'great snack', 'not impressed', 'disgusting', 'pop chips tops', 'not like taste', 'not like taste', 'amazing', 'popchips', 'fantastic mix popchip goodness', 'popchips variety pack', 'popchips', 'yummy popchips', 'yum love pop chips', 'pop chips', 'great chip', 'deliciousness little calories', 'healthier better tasting option', 'absolutely delicious', 'sooo tasty', 'great chips', 'popchips hmmmm hmmm hmmm', 'loved', 'worth money', 'love pop chips', 'great chip substitute', 'great low fat no cholestrol snack', 'great chips', 'entire family loves', 'yum', 'chip lover', 'good', 'bbq terrific', 'excellent', 'excellent product', 'pop chips better tasting better regular chips', 'pop chips', 'popchips flavor variety', 'popchips', 'yummy', 'great natural potatoe chips low calories', 'taste great', 'love first bite', 'fantastic product', 'perfect', 'say yum', 'delicious even dont enjoy healthy food', 'pop chips yum', 'best chips ever', 'pop chips', 'yummy alternative high fat chips', 'yummy popchips', 'love pop chips', 'pop crisps', 'great product', 'not care liked bbq wondering best sellers', 'omg delicious', 'great chips', 'great product', 'great diet', 'grow', 'best chips', 'perfect pop chips', 'cents', 'interesting however found something else', 'love chips', 'tast great less lard', 'omg best snack ever', 'great price great taste', 'yum', 'g rock', 'popchips', 'yummy', 'not defeat purpose eating two bags', 'popchips review', 'great product great price', 'yummy', 'great item', 'excellent chips', 'perfect ww followers', 'variety pack packed lunches', 'loved flavor except salt pepper', 'good sampler pack various flavors', 'tastes pretty good', 'not care variety selections', 'beware addicting', 'yum yum love pop chips', 'ca not beat taste', 'great chips tasty', 'delicious alternative greasy traditional chips', 'great snacking alternative', 'great gluten free snack healthy', 'like one', 'pop chips', 'yummy yummies', 'great tasting chips alternative', 'mmm mmm mmm', 'better expected', 'great snack', '', 'love', 'snacker', 'loooooooove', 'pop chips best', 'great unique chips', 'great alternative fried', 'delicious', 'yummy healthy snack', 'popchips wonderfully tasty', 'popchips best', 'delish', 'different yummy', 'loved chips', 'great alternative regular potato chips', 'pop chips', 'yum', 'awesome chips', 'popchips rule', 'definite pop not baked fried', 'great chips love salt vinegar', 'beware hidden ingredients', 'popchips weightwatchers', 'pringles instant coffee stephen baldwin', 'barely chips bag', 'great snack', 'pretty delicious', 'great snack', 'popchips great', 'love snack', 'kids ate', 'awesome product', 'short sweet', 'happy', 'popchips satisfy salt crunch craving', 'really tasty others little chemical tasting', 'tasty', 'topchips', 'yummy', 'salty', 'love popchips', 'awesome snack', 'yum', 'loved chips', 'gotta love em', 'popchips', 'fun game', 'yum', 'love', 'healthy tasty', 'pop chips go', 'popchips love', 'great snack', 'popchips variety box', 'pop chips rule', 'pop chips flavor variety pack', 'pop chips love', 'thoughts product', 'love love love', 'delicious', 'yum', 'really not like', 'yummie', 'strong flavors', 'love em big fat belly', 'yum', 'great taste crunchy', 'low calorie tasty snack', 'great chips', 'popchips new favorite snack', 'pop chips', 'popchips', 'delicious healthy chips', 'new favorite munchies found', 'good snack choice', 'great snack', 'love chips', 'pop chips rock', 'yummm', 'taste fat', 'love love love chips', 'tasty potato chips low calories great flavor', 'great guiltless snack', 'pop chips rock', 'yum', 'picky eater loves flavors', 'treat day', 'pop chips great', 'excellent thumbs', 'best snack food', 'pop chips variety', 'healthy delicious', 'great idea', 'flavors good', 'not everyone love', 'overrated', 'good', 'yummy', 'delicious', 'love tasty', 'pop chips yummy', 'kids liked one flavor', 'snack hour', 'popchips', 'love good variety pack', 'poor poor packaging', 'not bad', 'love love popchips', 'pop delicious', 'new favorite chips', 'healthy good', 'melts mouth', 'yum', 'great losing weight', 'low calories high taste', 'zippy', 'buy less', 'delicious', 'good', 'points plus weight watchers', 'satisfies salty snack craving', 'salty', 'tasty crunchy filling', 'awful', 'taste average insanely expensive', 'hidden sources msg ingredients', 'around forever not know', 'not great', 'healthy chips', 'not work', 'popchips vs baked lays baked lays taste much better', 'good not receive ordered', 'pop chips yum', 'great crunch solution', 'good chips not bad', 'get salt pepper box instead', 'ships apo', 'delicious', 'great fat free spicy', 'soooooo delicious', 'excellent store bought cookie', 'excellent everyday olive oil', 'yummy', 'reviewer totally right', 'price high', 'way range cost', 'delish smoked cheese buy', 'fantastic goat cheese', 'not tried product however', 'totally fantastic', 'awful barely describe', 'flavor getting better energy great', 'great energy drink without artificial ingredients', 'good stuff', 'tested trucker', 'best', 'best energy shot ever tasted', 'natural energy boost', 'like stuff', 'stuff works', 'rocket bottle', 'way better guayaki', 'fantastic natural energy', 'best energy shot smooth organic', 'great energy', 'great natural energy', 'favorite energy shot natural', 'delicious', 'fragrant delicious', 'clean delicious', 'thyme leaf', 'acne medicine', 'quality spices', 'never buy different brand', 'chopped clams', 'size seemed bigger', 'devine white clam sauce', 'new recipe gone bad', 'great chili', 'chili soup', 'dogs wild treats', 'maple syrup', 'love', 'great healthy snack', 'convenient filling calories lots protein great work lunch item', 'good nutrition right size', 'cats love tuna', 'awesome snack great product', 'handy size', 'sooo good', 'soooo good', 'college student gourmet', 'uncle rays without much taste', 'ketchup powdery coating excessive overdone gritty', 'not quite old dutch much better herr', 'good taste enough heat', 'tasty chips', 'great chips great flavor', 'great taste okay crunch', 'good people bought meh', 'unbelievable deal hard find pruduct', 'no stale chips cheap', 'zesty spiced', 'uncle rays barbeque chips', 'uncle ray bbq chips best', 'please not waste money', 'sure not taste like ketchup', 'great chips', 'vinegar', 'uncle ray kosher dill potato chips', 'not packets', 'disguising weight change', 'not recommended', 'thanks', 'plain', 'america favorite cake', 'duncan hines cake miss', 'contents shrunk', 'lost old friend', 'use pound cake', 'great not good back day teen', 'great product', 'excellent lemon juice', 'handy', 'realemon juice amazon', 'yum yummy yummier', 'health', 'best yet', 'best energy drink hands', 'cheaper anywhere else', 'choice formula', 'family formula', 'good lots cans', 'happy', 'priced', 'read read well', 'baby loves milk', 'enfamil premium power pk', 'great product', 'best everyday cookie', 'great cookies', 'food not unbalanced', 'healthy alternative kibble canned raw diets', 'great food', 'great food', 'great product willing work', 'otto likes', 'picky puppy', 'sojos original', 'caution poorly balanced nutrition', 'swiss chalet', 'not expected', 'great service', 'loved', 'lollipops', 'not pictured', 'made china', 'cute pops', 'slightly funny taste begin not stop eating', 'great birthday themed party', 'fun stuff', 'shipping', 'small swirled lollipops', 'perfect lollipops', 'false advertising', 'cute', 'great product', 'cute small lollipops arrived broken', 'choclate', 'great item', 'heavenly action', 'chocolate heaven', 'caramel chocolate', 'none greater', 'mints awesome', 'altoids smalls', 'nice little mints pricey', 'altoids mini mints tins', 'altoids smalls wintergreen', 'tasty', 'not breath mints', 'wintergreen', 'fresh', 'great lunch', 'love reusable containers', 'love em great', 'huge hit office', 'altoids', 'love', 'excellent green tea', 'enjoyable green tea', 'great price great quality', 'excellent', 'good perker upper', 'sublime fragrance taste', 'delicious', 'one best', 'smells like heaven', 'yummy', 'great pancakes waffles whole lot', 'best gluten free baking mix', 'pamela wholesale baking pancake mix', 'tastes awesome easy make', 'best value', 'great gluten free baking mix', 'described', 'pamela flour', 'gf flour power', 'pancakes cookies', 'pamelas baking mix', 'gluten free best flour', 'better gluten', 'great way start day', 'gluten free feel good', 'surprisingly good someone opposed gf products', 'gluten free talent', 'not like', 'love', 'delicious alternative soda', 'excellent soda alternative', 'sweet treets', 'sugar', 'love love love', 'tasty convenient', 'great idea yummy product', 'plum best', 'love', 'great adults', 'would buy', 'yum yum mishmash', 'awesome idea', 'yummy son loves', 'great tasting plum tot', 'month old daughter old twin niece nephew love', 'great product brilliant packaging', 'great traveling throwing diaper bag', 'great invention tasty healthy', 'safety instructions coca tea', 'great substitute sweetener', 'great product', 'great stuff', 'good container could better', 'sugar substitute', 'agave syrup', 'healthy sweetener', 'great way replacing sugar', 'could good', 'best', 'go sweetner', 'healthy stuff', 'excellent sweetner', 'great buy', 'weigh oz not fluid ounces', 'caramel flavor excellent baking toppings tips using agave', 'agave nectar', 'sweet success', 'yummy', 'best price agave nectar found', 'jarred paradise', 'juicy jays', 'great', 'delicious', 'not waste money', 'great product awful price', 'false advertising', 'expensive', 'dented', 'cento time', 'little disappointing', 'great italian', 'p not really', 'damaged cans', 'picture shows dop not', 'best', 'dented cans', 'cento san marzano', 'best value genuine article prime', 'not dop certified organic', 'beware not p certified', 'love except price', 'cans terribly banged dented', 'different product photo', 'cheap imitation not buy', 'false advertising', 'not get order', 'not dop', 'squism needs help', 'damaged merchandise', 'excellent', 'good coffee', 'coffee princess loves addiction', 'great coffee', 'great coffee great price', 'like', 'community coffee', 'excellent taste', 'community coffee', 'worst coffee ever', 'taste good', 'acceptable inexpensive great cold brewed', 'hazelnut coffee smells tastes like buttered popcorn not much like hazelnut', 'great flavor', 'ok price', 'community hazelnut coffee', 'great choice little dogs', 'yorkiepoo loves', 'healthful treat dogs', 'not take smell', 'beautiful fresh came easrly v yey', 'tasty fruit', 'fresh fruit dark chocolate', 'cameron coffee', 'nice coffee', 'good chocolate taste', 'better expected', 'amazing', 'meh', 'must allergic', 'loses taste fast', 'great gum', 'great product real garlic juice', 'staple', 'garlic juice', 'spray garlic', 'not edible', 'roasts smooth brew', 'guests love', 'bland', 'perfect ice tea', 'love love love coffee', 'wow', 'great price', 'rip price', 'best', 'huge success', 'koala crisps rock', 'real truffle oil makes difference', 'best flavor', 'perfect gift touch southwest', 'addicted', 'completly addicted love cant get enough', 'good others', 'great taste', 'prefer whole slices', 'nice pantry', 'not taste good', 'maybe not get', 'bleh cane juice ingred list', 'stuff delicious', 'pineapple flavored coconut water indonesia something really need', 'terrible flavor', 'lots flavor not sweet', 'coconut water', 'add sugar', 'n e coconut water', 'really good product', 'best ever', 'amazing even trendy', 'needs bigger splash', 'good taste not everyone', 'sweet not sweet', 'tasty', 'bland', 'really like sweet', 'tasty', 'great taste not sweet refreshing', 'not sports drink', 'best drink earth', 'delicious refreshing', 'new formulation not good', 'looking something little pina colada', 'n e coconut water splash pineapple', 'love stuff', 'colic acid reflux babies try', 'fan', 'best organic milk baby switched similac soy', 'buy elsewhere', 'great product', 'detailed reply company infant feeding dha ara', 'kleri tea works great', 'cute item', 'cute idea', 'not im used hey dietetic healthy', 'delicious nutrient packed fast', 'not corn muffin cornhusker', 'best healthy muffin', 'spray mix', 'yummy', 'dog loves', 'lovely', 'love colors', 'metallic pearl sheen airbrush colors', 'misleading', 'calorie packs nutter butter dipped delight bars', 'amazing', 'delicious low point value ww', 'love candy', 'best', 'saving grace green mountain coffee', 'nantucket blend k cups', 'smooth coffee highly recommended', 'price surprise', 'favorite', 'good coffee', 'cats love', 'cat hates', 'hard please kitty loves', 'cats love food', 'lives daily essentials pound bag cat food good food good price', 'great deal', 'cat digs', 'cat food', 'cats love', 'great value', 'great little treats', 'delicious', 'tasty', 'best pizza ever', 'pretty good dough', 'krinos tahini', 'best tahini ever buy lot', 'bitter', 'excellent hummus baba ganoush', 'best tahini', 'good hummus result', 'really make', 'white pear delight', 'excellent wine going make two right away', 'great wine', 'good kit', 'good wine made modifications', 'sweet delightful wine', 'not bad like tropical riesling better', 'simply amazing usual', 'crowd pleaser', 'white pear chardonnay', 'perfect water breaks', 'great healthy dog food dogs food allergies', 'great allergy dog', 'got wrong food dog ate', 'great dogs chew food', 'best dog food no ear infections', 'great alternative science diet allegry diets', 'jja', 'quality comes high price', 'king seasoning salts', 'simply best', 'excellent product life saver', 'happy face', 'tastes awesome looks beautiful', 'great oolong price', 'nice flavor great value', 'love tea', 'fine quality tea', 'quality tea', 'tea okay teabag not', 'found dollar store', 'tastes good', 'wu yi', 'not tea', 'excellent', 'crab cakes delight', 'looking different flavor', 'price cannot correct', 'best case', 'omg cookies', 'good', 'great cookies', 'delicious', '', 'smooth taste good hot iced', 'tasty', 'strong flavor decaf brand', 'great decaf', 'rich smooth taste', 'meh', 'doubts impressed', 'fine breakfast coffee drip coffee maker', 'great coffee not keep wired night', 'reminds demi tasse', 'yet another coffee comes town', 'not impressed', 'put money mouth first decaf stand', 'wonderful aroma taste careful opening bag', 'best decaf ever', 'mmmm nothing like good cup coffee', 'gourmet coffee decaf lovers', 'great way start finish day', 'excellent tasting coffee naturally decaffeinated', 'pretty good decaff', 'unexpectedly surprisingly good', 'love aroma great taste', 'smooth decaf', 'decaff quite excellent', 'full flavor smooth not punch bitterness', 'robust real coffee taste without caffeine', 'one best decaffeninated coffees tasted', 'nice late night cup', 'good coffee nothing extraordinary though', 'good quality coffee decent price', 'good flavor', 'delicious decaffeinated', 'excellent smooth flavor', 'good coffee', 'good cup decaf', 'decaf never tasted stars', 'good pricey', 'better galaxymoney chain coffee', 'good coffee', 'good mellow basic coffee', 'good decaf', 'smooth evening jazz cafe style coffee', 'pretty good go dessert', 'good cup decaf', 'unbelievably rich flavor', 'delicious not bitter', 'coffee snob reviews pre ground decaf', 'excellent quality value', 'intoxicating', 'mellow flavor no chemical aftertaste', 'great not like decaf', 'like', 'delicious without shakes', 'quailty coffee region price', 'another good product melitta', 'great coffee flavor still know decaffeinated', 'decaf coffee', 'nice smooth coffee', 'rich no bitterness', 'rich full', 'good half caf blending', 'goooood coffee', 'nice strong blend', 'smooth rich coffee', 'no complaints', 'surprisingly good', 'great drink dinner', 'exceptional coffee', 'good packaged ground coffee', 'smooth robust', 'surprise', 'delicious', 'excellent', 'unparalleled taste', 'amazing', 'oldest soft drink still best', 'made michigan since', 'crisp refreshing not tart', 'best soda ever', 'low calorie cocktail idea fresca peach spritzer', 'chocolot', 'excellent chocolates', 'great chocolates', 'deeee licious', 'great cakes', 'quantity', 'dog loves', 'great price', 'puppy dogs love', 'dog loves', 'loves', 'wonderful candy', 'perfect car trips', 'adorable great gift', 'buying two', 'great gift foodie life', 'excellent gift cook', 'great gift idea', 'fantastic experimental chef', 'first class company wonderful offerings', 'real customer service', 'great great great', 'unique gift surprising amount salt', 'really great product', 'review correction', 'love', 'pricey nice selection salts', 'vials arrived broken', 'high risk not buy', 'excellent starter set', 'indigestion major proportions', 'specialty party item', 'delicious', 'chocolate go wrong', 'chocolate liquor cups', 'scottie', 'no reaction', 'awful', 'awful', 'totally satisfying', 'love stuff', 'fresh high quality', 'lamb', 'great spice good price', 'nice polyvalent spice', 'wonderful spices', 'great spice blend', 'amazing spice', 'hit miss yet erin baker fixed everything', 'super yummy', 'breakfast cookies', 'good snack children', 'dont think real chocolate', 'great mid morning snack', 'best breed', 'tastes surprisingly good', 'poor quality control moldy', 'excellent taste handy', 'superman snacked eb', 'erin baker organic cookies', 'great cookie smaller size', 'healthy breakfast lover', 'erin wanna marry', 'good', 'not put sleep', 'bet life', 'great running recovery', 'really like', 'delicious tart cherry concentrate', 'good stuff', 'excellent', 'tart cherry concentrate', 'cheaper brands', 'tastes like fresh cherries', 'marathon runner', 'helps sore joints muscles', 'truly concentrated juice', 'nice caramel flavor', 'cafe excellence crazy caramet whole beans pound', 'sooo yummy', 'loved', 'breakfast dishes done differently', 'great ingredients', 'great sauce', 'good soy sauce not special mainly good unique gift', 'outstanding product', 'gets vote', 'surprise', 'better anything supermarket', 'though kikkoman good', 'non gmo', 'best soy sauce ever', 'great tasting sea salt iodine', 'great deal', 'great marinade', 'awesome stuff', 'delicious tea', 'every day green tea', 'best tea ever freah bright clean', 'tea review', 'wonderful tea', 'awesome cornmeal', 'royal canin cocker', 'perfect cockers', 'dog loves food', 'great food', 'buster loves dog food', 'happy dogs', 'fast great service', 'good food', 'happy dog', 'great deal', 'awesome', 'awesome drink', 'happy found product', 'flavor closer salad dressing', 'great product', 'nice medium brew', 'best coffee', 'good brand', 'delicious', 'ingredients take seconds read', 'minty flavor', 'could use', 'great machine', 'taste', 'teeny tiny little treats good healthy reward following commands', 'great training', 'perfect corn syrup free replacement candy', 'yummy healthier alternative sugary snacks', 'yummy', 'pricey flavorful', 'delish', 'grandson loves', 'not gluten free', 'get lot lot uses', 'por kwan chilli paste w sweet basil leaves hits spot vegetarian dishes', 'dog likes lot', 'happy camper', 'usa chicken stix', 'made usa', 'favorite', 'thin', 'not advertised', 'small diameter good small dogs not lb dog', 'sticks toothpicks compared redbard bully sticks', 'bully sticks', 'bully stix', 'vendor ripped cultures vendors', 'allday energy', 'good quality good price', 'expensive worth', 'one best sweet hot sauces', 'oh nuts', 'baby white popcorn tasty no hulls get teeth', 'crispy light', 'pops well not much flavor', 'not hull less popcorn even close', 'good', 'rip alert', 'poor product', 'tops popcorn world', 'great little mini popcorn', 'average taste', 'amish country baby white popcorn', 'spoiled popcorn', 'good stuff', 'good popocorn', 'caveat', 'popcorn lovers love popcorn', 'good stuff', 'great', 'best popcorn ever', 'great popcorn', 'keep poppin', 'tender', 'shipping insane', 'enjoy', 'favorite popcord', 'good popcorn', 'best popcorn', 'popcorn get better', 'amish baby white popcorn', 'best', 'tasty popcorn kernels small hot air popcorn popper', 'wow worth cost tender white hulless', 'amish country baby white', 'great hull less popcorn', 'yummy', 'fabulous popcorn', 'wonderful', 'great product little pricy worth', 'great popcorn small children', 'worst popcorn planet', 'excellent popcorn', 'best popcorn ever tasted', 'popcorn', 'nonthing deadheads', 'amish popcorn', 'delicious popcorn', 'baby white popcorn', 'great popcorn terrible price shipping', 'amish county baby white popcorn not really stock', 'wabash valley farms amish country baby white popcorn', 'great popcorn', 'yummy popcorn', 'small much shell not enough white fluffy part', 'best popcorn ever', 'microwave popcorn', 'wonderful', 'love', 'tad small wife taste kids love', 'small good', 'good flavor', 'disappointing', 'great little conversation piece', 'dispenser small', 'makes excellent biryani', 'favorite ramen', 'great value convenient ramen', 'great flavor', 'tastes great cheaper locally', 'tastes great love hot spicy bad price', 'great spicy flavor', 'not', 'amazing last bite', 'good', 'good choice', 'chicken noodle', 'fantastic hot meal', 'best around', 'not good', 'called toasty tasty cherry', 'good tea strong cherry aroma', 'water nothing', 'excellent quality', 'bottles instead usual', 'water pets', 'cloudy means impurities', 'talkingrain spring water', 'awful', 'spring water', 'shipping packaging poor', 'great tasting water', 'best water ever', 'good water comes price', 'great water', 'delicioius water not carry', 'highly recommend', 'happy purchase', 'awesome stuff', 'could drink stuff', 'good could beverage', 'super soft healthy cat', 'cats not eat', 'excellent product cats', 'tip pop top lids', 'high quality less cost', 'happy cats', 'real food cats', 'stars thumbs', 'cats go wild stuff', 'cat puked eating runny slop', 'cat loves food', 'cats not eat', 'happy cats happy', 'whole peas good food', 'poor value money', 'excellent grain free option', 'great food', 'perfect cat food older cats', 'best cat food', 'good feline uti', 'palatable healthy', 'healthy love', 'wonderful food perfect allergic kitties', 'far good', 'holistic select cat food', 'meh', 'no worries', 'yummy popcorn', 'really nice taste', 'love tea', 'great product poor packaging', 'great dark chocolate guests', 'chocolate good eat', 'actually pretty good', 'best cereal ever', 'love cereal', 'better tasting healthier high fiber cereals', 'best stuff ever', 'stuff sooooo good', 'seaweed rice', 'deliciously seasoned lite crispy', 'almost expired seaweed', 'great snacking', 'tasty', 'contains msg', 'mouth strong anus weaker', 'one best salsas', 'spicy', 'jolokia salsa review', 'good brand food', 'fabulous product', 'absolutely awesome', 'pasta', 'good', 'thought exceptional', 'pasta lovers dream', 'italian born pasta lover gives stars', 'fibergourmet light penne', 'fabulous', 'fantastic', 'real pasta half calories taste', 'great calorie cutter', 'great pasta', 'excellent alternative regular gatorade', 'great mild coffee', 'best coffee ever', 'island coffee', 'perfect work', 'coffee mate creamer', 'better packaging', 'shipped great', 'no broken creamers', 'coffee mate coffee creamer hazelnut', 'high quality fresh tea', 'powder instead leaf', 'avoid seloler', 'best green tea ever', 'cat not go near', 'simply wild chick brown rice cats', 'double pleasure', 'great tea settle stomach', 'plain gross', 'short fill', 'great multi infusion jasmine dragon pearl green tea', 'date chocolate', 'dissapointed', 'fantastic', 'one favoritte foods', 'wow', 'taste good', 'heinz no', 'really good stuff', 'waste money', 'deliciously scrumptious', 'best ever', 'amazing', 'forget molecular gastronomy stuff rockes coffee creamer', 'big tub salt', 'give watermelon citron sea salt', 'furniture polish taste', 'yes live eat', 'prime rib beef jerky', 'love cashew butter', 'dented cans', 'good value', 'goes great black beans rice', 'yummy', 'great sweet organic corn bpa not sure looks like eden cans', 'hit', 'warm wonderful', 'great healthy hot great tasting vegan meal go', 'quick easy tasty', 'noodles not good', 'love', 'horrible', 'love', 'yum', 'one favorites', 'soup entree unpopular', 'yum yum', 'dried', 'mostly dry', 'absolutely delicious', 'like gamble buying st patty dried fruit basket crap shoot', 'items gift basket bad old stale', 'nice fresh', 'best truthfull company', 'passion', 'tasty sweet', 'yummy', 'best beef jerky ever', 'wonderful beef jerky addiction waiting happen', 'beef jerkey amazing', 'good halal jerky', 'aluminum free', 'soda', 'baking soda bomb', 'strictly best', 'best coffee', 'fantastic coffee best ever', 'drinking love latin america aroma', 'bitter', 'treat best coffee', 'make day', 'love weavers fan', 'love soup', 'love', 'nt', 'not great', 'fisher pecan chips', 'little sweet', 'best market', 'yummy', 'not oz bag', 'happy hubby', 'mango anytime', 'ca not find anywhere else', 'best bar', 'great snack', 'another husband favorite', 'new granola bar', 'best gf pancakes', 'better mixes', 'disappointed gluten free not dairy free', 'gross', 'best gluten free mix ever', 'yuck', 'snickerdoodles', 'wonderful', 'might life saver', 'best pizza since gluten free', 'much', 'gluten free bisquick', 'great solution', 'good pancakes not need syrup need syrup', 'really good product not good real bisquik', 'great pancakes', 'excellent product', 'great pancakes', 'not fan', 'go ahead eat aluminum', 'white brown rice flour matters big time', 'disappointing pancakes', 'indigestion', 'not impressed', 'gritty no reason', 'bummer blah pancakes', 'not taste good', 'sugar sugar sugar', 'gluten free bisquick pancakes', 'love gluten free bisquick', 'fantastic priced', 'gf bisquick', 'best tasting ever gluten free bisquick', 'celiac friendly', 'really good mix', 'like old bisquick eat', 'love', 'almost like regualr pancakes', 'light flourer', 'bisquick not aluminum free', 'happy gluten free bisquick', 'like real thing', 'makes nice pakcake', 'fantastic pancakes', 'best purpose gluten free mix tried', 'happy tummy', 'gluten free bisquick great tasting pancake mix', 'ingredients', 'delicious', 'delicious', 'great baking aid', 'real gift us gf', 'delicious pancakes', 'gluten free years best mix ive tried', 'trusted name', 'love', 'yummy', 'gluten free good taste', 'not impressed', 'way sweet', 'stop baking', 'like remember regular bisquick', 'finally tasty gf baking mix', 'one greatest gluten free products found', 'great', 'great gluten free dairy free option make lots yummy food', 'perfect pancakes', 'makes wonderful red lobster cheese biscuits', 'bisquick gluten free', 'oh', 'disappointment', 'practical yumminess', 'almost good non gf', 'needs larger boxes', 'tasty pricey', 'better expected', 'great pancakes', 'love pancakes', 'great product perfect gluten free households', 'great taste', 'makes great pancakes', 'amazing', 'gluten free bisquick', 'good reviews', 'ca not tell difference regular pancakes waffles', 'awesome', 'great biscuits pancakes', 'makes great biscuits', 'yahoo bisquick', 'bisquick gluten free', 'best pancakes', 'tried best', 'consistent tasty results', 'gram', 'gluten free delicious', 'great gf baking mix', 'good product expensive', 'worst pizza ever', 'delicious', 'yummmmm', 'amazingly good', 'yeah pancakes', 'yum easy', 'wonderful great tasting', 'quick easy', 'wow pancake satisfaction last', 'good cobbler', 'ah finally good ol dumplings', 'one best', 'yummm', 'thank goodness bisquick gluten free', 'pretty good', 'best mix especially waffles', 'love', 'bisquick gluten free', 'best', 'tasty biscuits', 'gf please hear', 'excellent product pricey not enough product box family', 'ok expensive', 'bland bland bland', 'bugs beware', 'great things', 'life saver', 'total scam', 'love', 'like original bisquick', 'good surprise', 'love product', 'gluten free bisquick', 'gourmet pancakes', 'like bisquick remember', 'yummy gluten free dairy free pancakes', 'great cobbler', 'works like bisquick', 'grainy texture', 'best ever', 'good gluten free pancakes', 'bisquick gf mix', 'makes great pancakes', 'best pancake mix far', 'great product', 'wallpaper paste', 'bisquick good', 'works', 'great', 'bisquick gluten free pancake mix light fluffy healthier breakfast', 'love', 'great pancake mix', 'yea gf', 'good still gritty', 'fantastic', 'perfect', 'keep stock shelf', 'best gluten free pancake mix', 'best gf mix', 'godsend gluten intolerant people', 'acutually tastes good', 'no way', 'great', 'amazing', 'bisquick gluten free', 'music belly', 'makes great pancakes', 'finally', 'amazing', 'nummy', 'perfect pancakes enough said', 'great stuff', 'bisquick gf delicious', 'really good gluten free pancakes', 'great alternative', 'excellent product versatile convenient', 'pretty good', 'great gluten free product', 'awsome', 'good regular bisquick', 'everyone loves gluten free bisquick', 'great simple gf mix', 'easy tasty', 'yuck not waste money', 'finally', 'bit disappointing', 'good stuff', 'bisquick', 'yay', 'great product', 'good celiacs', 'love bisquick amazon', 'gluten free not always taste free', 'best gf pancake mix', 'great celiacs disease', 'great choice gluten free', 'wonderful item wish', 'stars taste gf kids', 'thank', 'simple versatile', 'love', 'excellent box small', 'not think would good great', 'solid gf mix', 'gluten free pancakes', 'gf bisquick never disappoints', 'tasty non corn muffins', 'great product', 'great pancakes', 'perfect', 'gluten free bisquick', 'gluten free bisquick review', 'bisquick gluten free', 'great', 'makes proper pancake', 'not pancakes', 'cheapest place amazon', 'delicioso', 'yummy', 'best', 'absolutely lifesaver', 'product celiac', 'gluten free must', 'best road snacks health', 'not particularly good', 'potent', 'product great price insane', 'tastey drops', 'omg not buy', 'awesome', 'great', 'great product great customer service', 'perfect blend spice vinegar', 'hannah pickled sausages', 'great food company', 'mushy yucky', 'hannah red hot pickled sausage gallon', 'best', 'difficult find tastes great', 'unique tart flavor delicious', 'tantalizing flavor scattered distribution', 'great flavored tic tacs', 'pink perfection', 'fresh product', 'pink grapefruit forever', 'long lost find', 'hope go pesticide free organic certified', 'love salsa', 'tasty spicy rich salsa', 'key lime pie gum extra', 'great stale', 'great gum', 'quite experience', 'good gum', 'yummmmmazing', 'yummy gum', 'love new dessert gums', 'words cannot describe wonderful extra dessert delights gum', 'tastes like real thing', 'delicious', 'key lime gum', 'amazing', 'awesome taste', 'delicious dessert replacement dieters', 'hydrogenated oils', 'pleasantly surprised', 'tasty', 'willy wonkalicious', 'yummy', 'key lime pie american tradition get flavor right', 'key lime gum really', 'best gum ever', 'shocked amazing', 'key lime sugarfree gum', 'watery', 'absolutely delicious', 'sure puts chalk chalkolate', 'dark chocolate cocoa', 'try grove square instead', 'seriously', 'bad reviewers need stir', 'aftertaste', 'another yummy', 'taste like muddy water maybe date', 'awful', 'yummy dark chocolate', 'artificial taste', 'delicious', 'yuck sucralose flavor no chocolate', 'great product', 'nasty watery drink', 'martha white chocolate chocolate chip muffin mix', 'best muffins world', 'easy make also', 'quick easy delicious', 'worst cookies ever', 'horrible', 'best', 'rave reviews favorite vegetable', 'no no', 'not taste good', 'yes real excellent coffee', 'darn good', 'great biscuits', 'best', 'moore marinade gluten low sodium msg free', 'great gluten free lifestyle', 'hard control quantity', 'morton sea salt', 'great morning cup', 'coffee good not strong flavor', 'great coffee', 'great peanuts', 'great tasting diet tea natural ingredients', 'not handle caffeine not', 'not waste money', 'best energy shot', 'not good', 'wow', 'missing action', 'disappointed', 'delicious', 'best babka', 'worth every penny', 'best peanut butter made', 'great', 'item covered walnuts needs allergens listed', 'babka', 'fantastic', 'delicious hear', 'absolutely delicious', 'best', 'good product', 'rosamonte especial', 'always good', 'best yerba mate', 'follow recipe exactly', 'sometimes good mail order things', 'worst purchase ever amazon not useable', 'disgusting waste money', 'agree others b u r n e', 'amazon not live end', 'tasted better loose leaf rooibos', 'new rooibos tea', 'best matcha quality price', 'super delicious', 'not originally ordered boo amazon', 'poor quality product', 'price right', 'great tasting cocoa powder', 'outrageous', 'alive aware organic raw cacao powder', 'warning reviews not reflect actual product feb', 'awesome cacao', 'best', 'equidorian ojio arriba carillo raw oranic cacao', 'delicious imo helps weight loss', 'good flavor', 'odd fake flavor not recommended', 'great gum', 'received one', 'great snacks', 'son loves', 'tastes good lots crumbs', 'fantastic', 'yummy', 'yummy healthy snack love', 'great pinch portable healthy', 'son not like', 'good taste baby love', 'super healthy baby loves', 'healthy snack', 'not know would without', 'love', 'awesome', 'award winning awesome flavour', 'another true chews pup loves', 'perfect size toy breed', 'not ordered', 'great cooking oil', 'calories', 'perfect hard licorice lovers', 'dense licorice flavor', 'kind stale', 'tulsi sweet rose tea', 'great alternative coffee drinkers', 'delicious', 'drink puroast coffee', 'delicious coffee', 'ugh', 'nice alternative regular coffee', 'worst tasting coffee ever tasted', 'single worst coffee ever', 'best coffee ever', 'surprisingly good no nausea', 'good news bad news situation low acid drinkers', 'undrinkable', 'better starbucks', 'love coffee', 'full flavor non acidic best k cup far', 'weak', 'best medium roast coffee', 'wonderful coffee', 'best coffee k cups', 'timothy', 'best decaf ever', 'like good colombian coffee', 'really taste like pb j sandwich', 'yum', 'pb j', 'p j bars', 'year old loves', 'good go', 'go wrong', 'favorite flavor', 'simply perfect', 'yummy', 'yummy', 'perfect lunch boxes', 'go wrong', 'favorite', 'pb j', 'loved tartlets', 'omaha apple tartlets', 'best', 'great support', 'tart', 'taste wise star item', 'amazing', 'goji cacao maca yuck', 'miam miam', 'sweet paprika good everything', 'poor texture', 'treat', 'decadent snack', 'holy moly life', 'awesome chai', 'reminds italy', 'addicting', 'yummmmy', 'pretty expensive', 'great deal', 'awsome kids neighborhood loved us', 'go wrong', 'awesome deal', 'wow deal', 'rishi tea loose leaf tea bags', 'thanks carrying', 'one best snacks going', 'snyder best flavor', 'great', 'arrived broken not eligible return', 'absolutely delicious', 'good compared others', 'love flavia coffee', 'adding touch heaven without bother', 'omg good', 'extremely pricey one favorites', 'gets better', 'adorable basket makes nice presentation', 'quick arrival great basket', 'amazing flavor', 'restaurant taste home', 'graet find', 'wow really good', 'best golden berries ever', 'raw organic fair trade tastes great', 'totally ginger', 'love em', 'not bad instant healthy coffee', 'love', 'great taste health benefits', 'tastes great arrived days', 'yummy indian dhall', 'great able get', 'yellow split peas', 'dog treats', 'city steam not much steam brew', 'good', 'taste great', 'famous reason', 'hey', 'wow', 'god love cookies', 'barley edible crunch sugar', 'chewy chips ahoy vs keebler soft batch', 'awesome', 'keebler soft batch chocolate chip cookies', 'deelish cookies', 'melted', 'excellent stuff reasonabale price', 'kona subscriber weighs', 'kona best', 'medium roast kona coffee', 'wow expensive coffee', 'definately worth', 'coffee not great customer service', 'smoothest cup coofee ever', 'expensive taste know', 'hawaii roasters kona coffee review', 'gummy bears', 'yummy', 'yummy', 'works', 'cherry good', 'tic tac solution', 'good', 'great tasting little treats', 'tic tac yum', 'tic tac', 'delicious hard find', 'yummy', 'great product good price', 'great flavor shipped fast', 'house blend good coffee', 'wonderful fudge', 'good', 'delicious', 'whonu chocolate sandwich creme cookies delicious healthier major name brand', 'delicious', 'no guilt snacking grand babies', 'really good cookies', 'delicious', 'chock full amazingness', 'love', 'yummy soft peppermint', 'fantastic chicken noodle soup', 'not pictured messy appearance', 'mix scores big', 'wine rita', 'great', 'packaging sufficient', '', 'cute packaging put together', 'disappointed', 'not pictured', 'much shipping', 'warning warning alcohol sugars', 'okay weird flavors', 'twinings earl grey decaf tea kcups', 'good', 'acquired taste', 'never paid much', 'relaxing almost like something smoke', 'marley mellow mood lite half tea half lemonade', 'family loved', 'great source electrolytes', 'hammer nutrition fizz rocks', 'low carb alternative gatorade', 'great preventing cramps', 'taste not good', 'best cheetos', 'delicious', 'good continue long', 'soo good', 'good cat food', 'great good price', 'yum', 'natural coconut', 'best tasting far', 'world best drink', 'love', 'tiny bubbles makes happy not want share', 'not even close coconut water', 'best tasting coconut water tasted little pricey bottles', 'delicious', 'love stuff', 'favorite coconut water', 'decaf disapointed', 'disappointed', 'disappointing', 'variety', 'ddjj', 'great starting pack', 'variety matches current picture', 'received iced coffee iced tea holiday coffee', 'kcup brewers pack', 'k cups come packages', 'not summer items', 'worst summer ever', 'extremely disappointing', 'not ordered', 'unsatisfied', 'interesting assortment', 'deceptive like christmas sampler', 'unsatisfied', 'beware contains fragrance', 'ms roxy', 'great buy', 'great product value', 'bought', 'good body wash', 'good price great stocking', 'moisturizing skin softener great smell', 'fast delivery', 'great product', 'time product', 'man love stuff', 'great product lousey bottle design', 'good dry skin', 'thick body wash lathers easily sometimes use bubble bath deep moisture', 'excellent', 'great price', 'great body wash', 'pleased', 'sls full', 'love love', 'among worst candy ever produced', 'marianne', 'finally good k cup hot chocolate', 'better others still not quite', 'hot choc k cup', 'grove cocoa k cups', 'keurig hot chocolate', 'great cocoa', 'grandkids love', 'never without', 'great product', 'good drink', 'watery multiple settings', 'kids love', 'nummy', 'not bad using coffeemate chocolate creamer', 'great value', 'best hot cocoa yet', 'really tasty', 'best hot cocoa ever', 'great flavor', 'not bad not bad', 'delicious', 'k cups', 'excellent flavor', 'hot cocoa', 'yummy', 'tasty good weight watchers', 'sucralose', 'pleasantly surprised', 'rich thick cocoa surprisingly good', 'much better expected great kids', 'good price bad taste', 'excellent hot chocolate', 'perfect cocoa', 'not bad not bad', 'really good hot cocoa highly recommended', 'sugar sucralose', 'hot cocoa k cups', 'perfect', 'love flavor', 'love hot chocolate keurig', 'good taste comes small packages', 'kids love taste best', 'grove square hot coco k cups', 'good', 'taste artificial sweetner', 'love', 'hard believe', 'grove square single serve hot cocoa keurig', 'good hot chocolate', 'hot cocoa', 'best hot chocolate', 'grove square hot chocolate', 'best', 'delicious', 'best k cup hot chocolate', 'k cup cocoa', 'like hot chocolate great', 'amazon nut', 'rich smooth creamy', 'great cocoa', 'well worth money', '', 'horrible taste', 'oh please get envelope hot water', 'taste great', 'good hot chocolate', 'delicious cocolate', 'ugh not expecting lt', 'warms soul', 'received expired product', 'really good', 'convenient pretty good', 'worth', 'best hot cocoa k cup', 'yummy', 'best ever', 'good hot chocolate', 'tastes great', 'yummy fro amazon', 'hits spot', 'great taste whole family loves', 'great product great price pepermint outstanding', 'well pleased', 'yum', 'artificial sweetener yuck', 'funny taste', 'awesome', 'chocolate heaven', 'not good', 'tastes like diet product', 'good buy', 'listened bad reviews', 'excellent product', 'perfect hot choc variety box', 'hot cocoa', 'grove city hot chocolate', 'best tasting cocoa k cup available', 'great', 'great deal great cocoa', 'great product', 'good tasty', 'great', 'great', 'yum', 'yumm', 'good money', 'yummy', 'good not great', 'great assortment', 'great hot cocoa', 'bad trouble giving away', 'good hot chocolate', 'pretty good hot chocolate', 'yummy hot chocolate', 'yummy', 'tasty', 'great tasting great value', 'not good', 'best k cup hot cocoa', 'horrible', 'yummy', 'wondering', 'peppermint favorite', 'tastes', 'great hot chocolate reasonable price', 'grove square hot chocolate best', 'pleased', 'nasty', 'not bad price', 'yummy', 'winter delight', 'excellent hot chocholate', 'great', 'hot cocoa', 'favorite hot cocoa', 'good flavor wont break bank', 'best hot chocolate k cups', 'really awful', 'delicious', 'best hot cocoa', 'really good', 'good cocoa great price', 'great tasting cocoa keurig', 'yummy hot cocoa', 'yum', 'get paid', 'best', 'hot cocoa cups', 'surprisingly good', 'good hot cocoa', 'great cocoa', 'replicator time', 'creamy rich cocoa', 'great hot chocolate', 'not good', 'taste like diet', 'partially hydrogenated vegetable oil', 'weird taste sugar substitute', 'stay away artificial sweeatners', 'good taste bad product', 'good hot cocoa', 'tastes like hot sugar water', 'great tasting', 'ca not complain', 'splendid product exceeded expectations', 'great winter', 'mmmmmm mmm good', 'thanks best hot cocoa outthere', 'good ages', 'hot cocoa', 'yummy', 'great hot chocolate', 'hot cocoa k cups', 'hot chocolate seconds', 'downright awful', 'not good cafe escapes', 'sugar free', 'artificially sweet', 'disapointed', 'much higher hopes', 'hot chocolate', 'great', 'not greatest', 'grove square hot cocoa cups', 'taste smells like rubber', 'yummy', 'nice tasting cocoa', 'love', 'great product', 'yuck artifical sweetener', 'surprisingly good', 'really good hot cocoa highly recommended', 'much artificial sweetner', 'yummy', 'delicious hot cocoa', 'grove square hot cocoa cups milk chocolate single serve cup keurig k cup brewers count', 'not perfect better rest', 'excellent hot cocoa', 'fantastic', 'delicious', 'yummy', 'great cocoa', 'disapointing', 'dark chocolate lover best tried', 'not good', 'not bad not good either', 'bad taste', 'worst hot chocolate ever', 'great creamer added chocolate flavoring', 'contains trans fats', 'love hot chocolate', 'great', 'great cup cocoa', 'mmmmm plastic', 'description not mention sugar free', 'grove square', 'first ingredient trans fat partially hydrogenated oil', 'grove square hot cocoa cups dark single serve cup', 'chocoholic view', 'sucralose', 'great hot chocolate', 'sweet weak', 'surprisingly good', 'best hot cocoa keurig', 'along lines', 'great hot chocolate', 'hot cocoa right time', 'fast affordable good', 'disgusting', 'best hot cocoa keurig', 'great cocoa price', 'pleased', 'least not expensive', 'great dark cocoa', 'keurig hot chocolate', 'great taste great price', 'love', 'kcup hot cocoa', 'great tasting coco', 'easy kids love', 'love hot chocolate', 'tastes pretty good', 'grove square hot cocoa cups milk chocolate keurig k cups brewers count', 'great product great price', 'great value', 'grove square', 'great taste', 'smooth', 'gave try not good', 'yummy hot choc olate', 'great value super yummy', 'service', 'best keurig hot chocolate far', 'highly recommended hot chocolate', 'still looking', 'kids love', 'found secret', 'yummy', 'good cocoa', 'cocoa', 'not favorite', 'good chocolate', 'wonderful', 'nice flavor', 'good stuff', 'pretty good', 'acceptable k cup hot chocolate', 'much better cafe escapes', 'grove square hot cocoa keurig', 'delish', 'not worth bad concept', 'wish would known', 'not quality', 'cocoa not bad price horrible', 'w e k not worth cost', 'hot cocoa k cups', 'great pricing', 'soso', 'best chocolate taste', 'hot cocoa anyone', 'wonderful hot cocoa', 'like taste artificial sweetner ok', 'best k cup cocoa', 'tasty great price', 'great hot cocoa', 'wow', 'say diet', 'not good', 'grove square k cups', 'pretty good not bad others saying', 'hot chocolate', 'sweet cocoa', 'jz', 'best dark cocoa fat', 'good price', 'good hot cocoa', 'much better less expensive ordered keurig', 'best tasting hot cocoa', 'outstanding', 'rancho gordo beans fun', 'shortbread cookies', 'price great even crowd much better smaller flavorice', 'sooo good', 'beans wonderful', 'horrible dont buy', 'great product', 'easy use', 'stuffed baked potatoes', 'omaha chicken stuffed baked potatoies', 'taters', 'easy single lifestyle', 'pretty good', 'good', 'au gratin potatoes', 'best hash browns', 'tasted ok bit overpriced tho', 'good', 'not like picture', 'yum yum yum', 'like', 'rated way priced frozen meats', 'good', 'potatoes', 'best twice baked potatoes ever', 'tasty easy make', 'tasty perfect sized', 'yummy', 'tasty', 'quick easy taste great', '', 'kind potato steak', 'yum', 'tastes good', 'top quality salsa', 'best', 'lovely flour not frankenwheat', 'best flour pizza', 'perfect pizza pasta', 'wonderful product', 'pizza napoletana dough flour mangia', 'really good product', 'no cholesterol no sodium not sweet good taste', 'great product rip site', 'good great taste easy single guy', 'no fridge want meat', 'yummy', 'stay away company', 'excellent original greek olive oil', 'delicious', 'simply best olive oil best source', 'yum', 'delicious', 'waste time', 'wrong item shipped', 'great product', 'baby favorite flavors', 'earth best variety pack', 'good watery', 'love dinners amazon price higher retail', 'flavors stink mold', 'earth best dinners way runny', 'not fan bpa baby food jar lids', 'love earth best brand usually', 'excellent variety month old loves informed water largest ingrident weight', 'earth best best', 'baby best pre packaged', 'lot research brand', 'great variety means no picky eaters', 'product good amazon fulfillment poor', 'great variety', 'ok would like variety', 'almost price gerber better quality baby', 'dinner time earths best time', 'food delivery', 'not tasty', 'not favorite product', 'love meals', 'best baby food ever', 'price', 'child loves food', 'good variety good flavors', 'great variety pack', 'good variety may not everyone', 'baby loves', 'one favorite variety packs', 'son loves earth best', 'little sweet', 'good pricy', 'great coffee', 'great coffee possibly best tassimo', 'verona replacement', 'good coffee brews hot', 'gevalia melange maison corse', 'finally something good gevalia', 'happiness deep dark cup', 'not banana runts', 'worked great', 'vanilla tootsie rolls', 'not waste money', 'like texture', 'perfect sweet tooth coming gluten', 'cave man cookies crazy good', 'great healthy snack', 'good except rainforest flavor', 'cookies need work make home', 'taste awful', 'cavemen must wealthy', 'amazing', 'delicious', 'great', 'toasted sesame oil', 'tasty tasty tasty', 'yum', 'disappointing', 'love hot sauce', 'awesome sauce', 'great hot sauce people run', 'tasty hot sauce', 'hot flavorful', 'best sauce around', 'love stuff', 'great hot sauce', 'best around hot sauce', 'best hot sauce around', 'not hot', 'not hot not habanero', 'sauce shiznit', 'item described shipped time thanks', 'love', 'yum', 'yes really umm umm good', 'amazingly true flavors', 'laxative', 'wonderful tasty taffy', 'great good expensive brands', 'nice taffy', 'great taffy', 'big fan', 'maximum rave power', 'best ever latice tart', 'best sugar substitute', 'gold plated cereal', 'jelly belly best', 'far donut shop classics best pods tried', 'hard find new york glad amazon deliver', 'star price stars taste', 'absolutely best', 'tasty', 'contains food preservatives', 'good coffee', 'great selection provided', 'nice variety guests try flavor', 'unsorted assorted', 'like lot', 'nice plant', 'still alive', 'good stuff', 'goody good', 'tasty', 'yum', 'addictive', 'want', 'low quality', 'pop tarts work art', 'awful', 'delicious', 'tasty healthy snack', 'super superfoods super easy', 'best', 'best bloody mary mixer', 'mcclures bloody mary mix', 'bars', 'best iced tea', 'almost not quite', 'delicious', 'good thing', 'favorite k cup', 'green mountain compared tully french roast', 'love coffee', 'excellent choice', 'tastes like', 'great cup coffee', 'one favorite coffees', 'great french roast', 'green mountain k cups', 'greatest coffee', 'best show k cup french roast', 'great deal', 'another great green mountain coffee', 'great coffee great price', 'great new gmo free snack', 'delicious', 'shrimp stir fry', 'wonderful', 'best way buy kcups', 'delicious', 'almost bought', 'good product', 'kill cliff sports recovery drink', 'fantastic', 'good product', 'delish', 'not advertised', 'not full leaf pound not pounds', 'fluffy soft delicious sugary sweet', 'disappointed', 'reeks like chemicals', 'coconut water pineapple yummy', 'delicious', 'coconut water', 'yummy', 'awesome', 'vita coco water awsome', 'thirst quenching', 'finally coconut water like', 'refreshing delicious', 'excellent', 'delicious rejuvenating', 'great taste nice fruit flavor serve chilled', 'vita coco best', 'nutritional content brand not live label', 'gross', 'addicted', 'well', 'yuck', 'afternoon pick', 'unusual flavor', 'good use smoothies', 'great taste', 'vita coco', 'best coconut water flavor size', 'answer cramping problems', 'addicted stuff wore', 'vita coco', 'awesome tasting', 'advertised', 'favorite flavor', 'hydrating refreshing great tasting drink', 'like', 'vita coco pineapple best yet', 'great product convenient shipment', 'best tasting coconut water found', 'yummy', 'cold refreshing', 'best flavor light refreshing', 'not greatest', 'great coconut water right size', 'favorite', 'good taste', 'ambrosia', 'greatest oil since slice bread', 'excellent tea', 'bit strong', 'great simple coffee', 'nice balanced taste', 'great taste not bitter', 'caribou', 'mahogany k cups', 'lives appealing name', 'yum', 'love caribou mahogany', 'caribou coffee mahogany review', 'smooooth', 'best k cup', 'really excellent', 'disapointed', 'best coffee', 'best coffee ever', 'smooth flat', 'not like', 'love coffee', 'mellow full bodied', 'coffee lovers', 'caibou mahogany k cup', 'fave', 'favorite', 'caribou coffee mahogany', 'first impression chocolate', 'like hard find', 'rich delicious', 'wake call', 'delicious', 'nice flavor', 'bold k cups coffee', 'love', 'good coffee', 'wonderful dark coffee', 'cozy flavor tried', 'best coffee depression lifting mood', 'caribou coffee strong', 'yummy', 'amazed', 'great coffee', 'oooh like', 'new favorite dark k cup', 'best k cup', 'smooth tasty absolute dream come true enjoy bold dark roasts', 'good bold coffee', 'caribou mahogany', 'not like fresh gettin better', 'best overall coffee', 'excellent presence not smokey smooth finish', 'best k cup date', 'great coffee', 'great coffee', 'excellent coffee', 'yummy coffee', 'great coffee', 'fantastic stuff', 'great tasting coffee', 'best caribou', 'coffee good name good', 'burnt toast', 'love caribou', 'almost none', 'yum', 'great coffee', 'cute cute cute', 'surprising find', 'best', 'huge fan', 'awesome sauce', 'good malta baffling business model', 'service good', 'able eat bread', 'love taro', 'delicious easy', 'favorite thing brazil', 'delicous', 'best italian olive oil', 'mild taste delicious', 'great drink horrible price', '', 'omg best chocolate jelly belly', 'great stuff', 'not believe', 'one better discs', 'great coffee terrible price', 'best tassimo', 'good tasting cup joe', 'kona tassimo', 'weak coffee not good premium product price']"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "Preprocessed_Summary=[]\n",
    "for summary in tqdm(final['Summary'].values): \n",
    "    summary = decontracted(summary)\n",
    "    summary = re.sub(\"\\S*\\d\\S*\", \" \", summary).strip()\n",
    "    summary=re.sub(r'[^A-Za-z0-9]+',' ',summary)\n",
    "    summ=' '.join([i.lower() for i in summary.split() if i.lower() not in stopwords])\n",
    "    Preprocessed_Summary.append(summ.strip())\n",
    "print(Preprocessed_Summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ytBZVEs2CAaL"
   },
   "source": [
    "# [4] Featurization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9amw6tMZCAaL"
   },
   "source": [
    "## [4.1] BAG OF WORDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3hasoJ-_CAaN",
    "outputId": "12aa3f3f-083c-4de4-a6e7-3dbde6b5a905"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "some feature names  ['aa', 'aahhhs', 'aback', 'abandon', 'abates', 'abbott', 'abby', 'abdominal', 'abiding', 'ability']\n",
      "==================================================\n",
      "the type of count vectorizer  <class 'scipy.sparse.csr.csr_matrix'>\n",
      "the shape of out text BOW vectorizer  (4986, 12997)\n",
      "the number of unique words  12997\n"
     ]
    }
   ],
   "source": [
    "#BoW\n",
    "count_vect = CountVectorizer() #in scikit-learn\n",
    "count_vect.fit(preprocessed_reviews)\n",
    "print(\"some feature names \", count_vect.get_feature_names()[:10])\n",
    "print('='*50)\n",
    "\n",
    "final_counts = count_vect.transform(preprocessed_reviews)\n",
    "print(\"the type of count vectorizer \",type(final_counts))\n",
    "print(\"the shape of out text BOW vectorizer \",final_counts.get_shape())\n",
    "print(\"the number of unique words \", final_counts.get_shape()[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1dhfJZ7ZCAaR"
   },
   "source": [
    "## [4.2] Bi-Grams and n-Grams."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "u1Ma2LBfCAaR",
    "outputId": "a5208a4c-c0ad-4360-f021-b2e8715610a4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the type of count vectorizer  <class 'scipy.sparse.csr.csr_matrix'>\n",
      "the shape of out text BOW vectorizer  (4986, 3144)\n",
      "the number of unique words including both unigrams and bigrams  3144\n"
     ]
    }
   ],
   "source": [
    "#bi-gram, tri-gram and n-gram\n",
    "\n",
    "#removing stop words like \"not\" should be avoided before building n-grams\n",
    "# count_vect = CountVectorizer(ngram_range=(1,2))\n",
    "# please do read the CountVectorizer documentation http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html\n",
    "# you can choose these numebrs min_df=10, max_features=5000, of your choice\n",
    "count_vect = CountVectorizer(ngram_range=(1,2), min_df=10, max_features=5000)\n",
    "final_bigram_counts = count_vect.fit_transform(preprocessed_reviews)\n",
    "print(\"the type of count vectorizer \",type(final_bigram_counts))\n",
    "print(\"the shape of out text BOW vectorizer \",final_bigram_counts.get_shape())\n",
    "print(\"the number of unique words including both unigrams and bigrams \", final_bigram_counts.get_shape()[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "F--Xk5fhCAaV"
   },
   "source": [
    "## [4.3] TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6heiZFZ-CAaW",
    "outputId": "08103e90-4bd8-410e-b3dc-84a02e01aa33"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "some sample features(unique words in the corpus) ['ability', 'able', 'able find', 'able get', 'absolute', 'absolutely', 'absolutely delicious', 'absolutely love', 'absolutely no', 'according']\n",
      "==================================================\n",
      "the type of count vectorizer  <class 'scipy.sparse.csr.csr_matrix'>\n",
      "the shape of out text TFIDF vectorizer  (4986, 3144)\n",
      "the number of unique words including both unigrams and bigrams  3144\n"
     ]
    }
   ],
   "source": [
    "tf_idf_vect = TfidfVectorizer(ngram_range=(1,2), min_df=10)\n",
    "tf_idf_vect.fit(preprocessed_reviews)\n",
    "print(\"some sample features(unique words in the corpus)\",tf_idf_vect.get_feature_names()[0:10])\n",
    "print('='*50)\n",
    "\n",
    "final_tf_idf = tf_idf_vect.transform(preprocessed_reviews)\n",
    "print(\"the type of count vectorizer \",type(final_tf_idf))\n",
    "print(\"the shape of out text TFIDF vectorizer \",final_tf_idf.get_shape())\n",
    "print(\"the number of unique words including both unigrams and bigrams \", final_tf_idf.get_shape()[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XnzP-eZdCAaa"
   },
   "source": [
    "## [4.4] Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "e-IuUZsTCAaa"
   },
   "outputs": [],
   "source": [
    "# Train your own Word2Vec model using your own text corpus\n",
    "i=0\n",
    "list_of_sentance=[]\n",
    "for sentance in preprocessed_reviews:\n",
    "    list_of_sentance.append(sentance.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GIbKBSkRCAac",
    "outputId": "d72c6206-2c3f-4143-8c21-3f5b674310df",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('want', 0.9948499202728271), ('enjoy', 0.993760347366333), ('think', 0.9931143522262573), ('snack', 0.9930903315544128), ('flavorful', 0.9925112128257751), ('tasty', 0.992412805557251), ('heaven', 0.9923456907272339), ('overpowering', 0.9921022653579712), ('salty', 0.9920707941055298), ('tasting', 0.9920499324798584)]\n",
      "==================================================\n",
      "[('varieties', 0.9994068145751953), ('berry', 0.9993639588356018), ('popcorn', 0.9992774724960327), ('type', 0.9992654323577881), ('hands', 0.9992233514785767), ('wow', 0.9992210268974304), ('somewhat', 0.9992208480834961), ('come', 0.9992064833641052), ('tassimo', 0.9991840720176697), ('mccann', 0.999176025390625)]\n"
     ]
    }
   ],
   "source": [
    "# Using Google News Word2Vectors\n",
    "\n",
    "# in this project we are using a pretrained model by google\n",
    "# its 3.3G file, once you load this into your memory \n",
    "# it occupies ~9Gb, so please do this step only if you have >12G of ram\n",
    "# we will provide a pickle file wich contains a dict , \n",
    "# and it contains all our courpus words as keys and  model[word] as values\n",
    "# To use this code-snippet, download \"GoogleNews-vectors-negative300.bin\" \n",
    "# from https://drive.google.com/file/d/0B7XkCwpI5KDYNlNUTTlSS21pQmM/edit\n",
    "# it's 1.9GB in size.\n",
    "\n",
    "\n",
    "# http://kavita-ganesan.com/gensim-word2vec-tutorial-starter-code/#.W17SRFAzZPY\n",
    "# you can comment this whole cell\n",
    "# or change these varible according to your need\n",
    "\n",
    "is_your_ram_gt_16g=False\n",
    "want_to_use_google_w2v = False\n",
    "want_to_train_w2v = True\n",
    "\n",
    "if want_to_train_w2v:\n",
    "    # min_count = 5 considers only words that occured atleast 5 times\n",
    "    w2v_model=Word2Vec(list_of_sentance,min_count=5,size=50, workers=4)\n",
    "    print(w2v_model.wv.most_similar('great'))\n",
    "    print('='*50)\n",
    "    print(w2v_model.wv.most_similar('worst'))\n",
    "    \n",
    "elif want_to_use_google_w2v and is_your_ram_gt_16g:\n",
    "    if os.path.isfile('GoogleNews-vectors-negative300.bin'):\n",
    "        w2v_model=KeyedVectors.load_word2vec_format('GoogleNews-vectors-negative300.bin', binary=True)\n",
    "        print(w2v_model.wv.most_similar('great'))\n",
    "        print(w2v_model.wv.most_similar('worst'))\n",
    "    else:\n",
    "        print(\"you don't have gogole's word2vec file, keep want_to_train_w2v = True, to train your own w2v \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JEJGArtUCAae",
    "outputId": "943e0fc6-83f8-455b-ba53-8dd05428fc92"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of words that occured minimum 5 times  3817\n",
      "sample words  ['product', 'available', 'course', 'total', 'pretty', 'stinky', 'right', 'nearby', 'used', 'ca', 'not', 'beat', 'great', 'received', 'shipment', 'could', 'hardly', 'wait', 'try', 'love', 'call', 'instead', 'removed', 'easily', 'daughter', 'designed', 'printed', 'use', 'car', 'windows', 'beautifully', 'shop', 'program', 'going', 'lot', 'fun', 'everywhere', 'like', 'tv', 'computer', 'really', 'good', 'idea', 'final', 'outstanding', 'window', 'everybody', 'asks', 'bought', 'made']\n"
     ]
    }
   ],
   "source": [
    "w2v_words = list(w2v_model.wv.vocab)\n",
    "print(\"number of words that occured minimum 5 times \",len(w2v_words))\n",
    "print(\"sample words \", w2v_words[0:50])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EPjGCg7UCAag"
   },
   "source": [
    "## [4.4.1] Converting text into vectors using wAvg W2V, TFIDF-W2V"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oPxfYXhMCAag"
   },
   "source": [
    "#### [4.4.1.1] Avg W2v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sB4Y18rQCAag",
    "outputId": "c9f64dac-cc89-43e3-9820-fbc18c39a69e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 4986/4986 [00:04<00:00, 1024.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4986\n",
      "50\n"
     ]
    }
   ],
   "source": [
    "# average Word2Vec\n",
    "# compute average word2vec for each review.\n",
    "sent_vectors = []; # the avg-w2v for each sentence/review is stored in this list\n",
    "for sent in tqdm(list_of_sentance): # for each review/sentence\n",
    "    sent_vec = np.zeros(50) # as word vectors are of zero length 50, you might need to change this to 300 if you use google's w2v\n",
    "    cnt_words =0; # num of words with a valid vector in the sentence/review\n",
    "    for word in sent: # for each word in a review/sentence\n",
    "        if word in w2v_words:\n",
    "            vec = w2v_model.wv[word]\n",
    "            sent_vec += vec\n",
    "            cnt_words += 1\n",
    "    if cnt_words != 0:\n",
    "        sent_vec /= cnt_words\n",
    "    sent_vectors.append(sent_vec)\n",
    "print(len(sent_vectors))\n",
    "print(len(sent_vectors[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sKAEsZZLCAam"
   },
   "source": [
    "#### [4.4.1.2] TFIDF weighted W2v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pAVTG3brCAao"
   },
   "outputs": [],
   "source": [
    "# S = [\"abc def pqr\", \"def def def abc\", \"pqr pqr def\"]\n",
    "model = TfidfVectorizer()\n",
    "model.fit(preprocessed_reviews)\n",
    "# we are converting a dictionary with word as a key, and the idf as a value\n",
    "dictionary = dict(zip(model.get_feature_names(), list(model.idf_)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Tyxhz3XQCAap",
    "outputId": "e72f3ca0-7d29-4657-a107-c5d678514cf3",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 4986/4986 [00:31<00:00, 156.58it/s]\n"
     ]
    }
   ],
   "source": [
    "# TF-IDF weighted Word2Vec\n",
    "tfidf_feat = model.get_feature_names() # tfidf words/col-names\n",
    "# final_tf_idf is the sparse matrix with row= sentence, col=word and cell_val = tfidf\n",
    "\n",
    "tfidf_sent_vectors = []; # the tfidf-w2v for each sentence/review is stored in this list\n",
    "row=0;\n",
    "for sent in tqdm(list_of_sentance): # for each review/sentence \n",
    "    sent_vec = np.zeros(50) # as word vectors are of zero length\n",
    "    weight_sum =0; # num of words with a valid vector in the sentence/review\n",
    "    for word in sent: # for each word in a review/sentence\n",
    "        if word in w2v_words and word in tfidf_feat:\n",
    "            vec = w2v_model.wv[word]\n",
    "#             tf_idf = tf_idf_matrix[row, tfidf_feat.index(word)]\n",
    "            # to reduce the computation we are \n",
    "            # dictionary[word] = idf value of word in whole courpus\n",
    "            # sent.count(word) = tf valeus of word in this review\n",
    "            tf_idf = dictionary[word]*(sent.count(word)/len(sent))\n",
    "            sent_vec += (vec * tf_idf)\n",
    "            weight_sum += tf_idf\n",
    "    if weight_sum != 0:\n",
    "        sent_vec /= weight_sum\n",
    "    tfidf_sent_vectors.append(sent_vec)\n",
    "    row += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IjMcxjHfCAas"
   },
   "source": [
    "# [5] Applying TSNE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SPCsfz2fCAat"
   },
   "source": [
    "ol>\n",
    "    <li><strong>Apply Knn(brute force version) on these feature sets</strong>\n",
    "        <ul>\n",
    "            <li><font color='red'>SET 1:</font>Review text, preprocessed one converted into vectors using (BOW)</li>\n",
    "            <li><font color='red'>SET 2:</font>Review text, preprocessed one converted into vectors using (TFIDF)</li>\n",
    "            <li><font color='red'>SET 3:</font>Review text, preprocessed one converted into vectors using (AVG W2v)</li>\n",
    "            <li><font color='red'>SET 4:</font>Review text, preprocessed one converted into vectors using (TFIDF W2v)</li>\n",
    "        </ul>\n",
    "    </li>\n",
    "    <br>\n",
    "    <li><strong>Apply Knn(kd tree version) on these feature sets</strong>\n",
    "        <br><font color='red'>NOTE: </font>sklearn implementation of kd-tree accepts only dense matrices, you need to convert the sparse matrices of CountVectorizer/TfidfVectorizer into dense matices. You can convert sparse matrices to dense using .toarray() attribute. For more information please visit this <a href='https://docs.scipy.org/doc/scipy-0.18.1/reference/generated/scipy.sparse.csr_matrix.toarray.html'>link</a>\n",
    "        <ul>\n",
    "            <li><font color='red'>SET 5:</font>Review text, preprocessed one converted into vectors using (BOW) but with restriction on maximum features generated.\n",
    "            <pre>\n",
    "            count_vect = CountVectorizer(min_df=10, max_features=500) \n",
    "            count_vect.fit(preprocessed_reviews)\n",
    "            </pre>\n",
    "            </li>\n",
    "            <li><font color='red'>SET 6:</font>Review text, preprocessed one converted into vectors using (TFIDF) but with restriction on maximum features generated.\n",
    "            <pre>\n",
    "                tf_idf_vect = TfidfVectorizer(min_df=10, max_features=500)\n",
    "                tf_idf_vect.fit(preprocessed_reviews)\n",
    "            </pre>\n",
    "            </li>\n",
    "            <li><font color='red'>SET 3:</font>Review text, preprocessed one converted into vectors using (AVG W2v)</li>\n",
    "            <li><font color='red'>SET 4:</font>Review text, preprocessed one converted into vectors using (TFIDF W2v)</li>\n",
    "        </ul>\n",
    "    </li>\n",
    "    <br>\n",
    "    <li><strong>The hyper paramter tuning(find best K)</strong>\n",
    "        <ul>\n",
    "    <li>Find the best hyper parameter which will give the maximum <a href='https://www.appliedaicourse.com/course/applied-ai-course-online/lessons/receiver-operating-characteristic-curve-roc-curve-and-auc-1/'>AUC</a> value</li>\n",
    "    <li>Find the best hyper paramter using k-fold cross validation or simple cross validation data</li>\n",
    "    <li>Use gridsearch cv or randomsearch cv or you can also write your own for loops to do this task of hyperparameter tuning</li>\n",
    "        </ul>\n",
    "    </li>\n",
    "    <br>\n",
    "    <li>\n",
    "    <strong>Representation of results</strong>\n",
    "        <ul>\n",
    "    <li>You need to plot the performance of model both on train data and cross validation data for each hyper parameter, like shown in the figure\n",
    "    <img src='train_cv_auc.JPG' width=300px></li>\n",
    "    <li>Once after you found the best hyper parameter, you need to train your model with it, and find the AUC on test data and plot the ROC curve on both train and test.\n",
    "    <img src='train_test_auc.JPG' width=300px></li>\n",
    "    <li>Along with plotting ROC curve, you need to print the <a href='https://www.appliedaicourse.com/course/applied-ai-course-online/lessons/confusion-matrix-tpr-fpr-fnr-tnr-1/'>confusion matrix</a> with predicted and original labels of test data points\n",
    "    <img src='confusion_matrix.png' width=300px></li>\n",
    "        </ul>\n",
    "    </li>\n",
    "    <br>\n",
    "    <li><strong>Conclusion</strong>\n",
    "        <ul>\n",
    "    <li>You need to summarize the results at the end of the notebook, summarize it in the table format. To print out a table please refer to this prettytable library<a href='http://zetcode.com/python/prettytable/'> link</a> \n",
    "        <img src='summary.JPG' width=400px>\n",
    "    </li>\n",
    "        </ul>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4><font color='red'>Note: Data Leakage</font></h4>\n",
    "\n",
    "1. There will be an issue of data-leakage if you vectorize the entire data and then split it into train/cv/test.\n",
    "2. To avoid the issue of data-leakag, make sure to split your data first and then vectorize it. \n",
    "3. While vectorizing your data, apply the method fit_transform() on you train data, and apply the method transform() on cv/test data.\n",
    "4. For more details please go through this <a href='https://soundcloud.com/applied-ai-course/leakage-bow-and-tfidf'>link.</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 347
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2114,
     "status": "ok",
     "timestamp": 1547365772849,
     "user": {
      "displayName": "Applied AI Course",
      "photoUrl": "https://lh3.googleusercontent.com/-EsJzSyawCkQ/AAAAAAAAAAI/AAAAAAAADag/xYU9KO6AZf4/s64/photo.jpg",
      "userId": "06629147635963609455"
     },
     "user_tz": -330
    },
    "id": "Z379u6ElCAat",
    "outputId": "47a20627-9d10-45c8-fe40-ecd0726e33c5"
   },
   "source": [
    "# [5.1] Applying KNN brute force"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ejF91OEjCAaw"
   },
   "source": [
    "### [5.1.1] Applying KNN brute force on BOW,<font color='red'> SET 1</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4986, 12997)\n"
     ]
    }
   ],
   "source": [
    "import scipy\n",
    "#converting the matrix to densematrix\n",
    "final_dense=final_counts.todense()#(4986, 12997)\n",
    "print(final_dense.shape)\n",
    "x=final_dense\n",
    "\n",
    "\n",
    "#converting score into Postive and negative review\n",
    "def df_score(x):\n",
    "    if x<3:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n",
    "    \n",
    "y = final['Score'].apply(df_score)\n",
    "\n",
    "y=y.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rnetKp45CAaw"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train_shape :  2991\n",
      "y_train_shape :  2991\n",
      "x_cv_shape :  997\n",
      "y_cv_shape :  997\n",
      "x_test_shape :  998\n",
      "y_test_shape :  998\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "#spliting the data into train,cv and test. \n",
    "x_train,x_1,y_train,y_1=train_test_split(x,y,train_size =0.6,random_state=0)\n",
    "x_cv,x_test,y_cv,y_test=train_test_split(x_1,y_1,train_size =0.5,random_state=0)\n",
    "\n",
    "\n",
    "#priting the rows against train,cv and test\n",
    "print(\"x_train_shape : \", x_train.shape[0])\n",
    "print(\"y_train_shape : \", y_train.shape[0])\n",
    "print(\"x_cv_shape : \", x_cv.shape[0])\n",
    "print(\"y_cv_shape : \", y_cv.shape[0])\n",
    "print(\"x_test_shape : \", x_test.shape[0])\n",
    "print(\"y_test_shape : \", y_test.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of the model for Cross validation optimal-K: 9 is 85.37074148296593 \n"
     ]
    }
   ],
   "source": [
    "CV_Accuracy=dict()#making the dict. \n",
    "for k in range(1,30):\n",
    "    knn=KNeighborsClassifier(n_neighbors=k,algorithm='brute')#calling the Knn classifiers. \n",
    "    knn.fit(x_train,y_train)#fiting with Dtrain data \n",
    "    pred=knn.predict(x_cv)#predicting the label values with CV data\n",
    "    acc=accuracy_score(y_cv,pred)*float(100) #finding the accurarcy.\n",
    "    CV_Accuracy[k]=acc#storing the key valye pairs of K and accuracy. \n",
    "    \n",
    "#getting the optimal Value    \n",
    "optimal_k=max(CV_Accuracy,key=CV_Accuracy.get)\n",
    "\n",
    "#calling the Knn classifier with optimal value.\n",
    "knn=KNeighborsClassifier(n_neighbors=optimal_k,algorithm='brute')\n",
    "knn.fit(x_train,y_train)#fiting with Dtest data\n",
    "pred=knn.predict(x_test)#predicting the label values with Dtest\n",
    "acc=accuracy_score(y_test,pred)*float(100)#finding the accuracy. \n",
    "print(\"The accuracy of the model for Cross validation optimal-K: {0} is {1} \".format(optimal_k,acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "b_-boR2SCAay"
   },
   "source": [
    "### [5.1.2] Applying KNN brute force on TFIDF,<font color='red'> SET 2</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4986, 3144)\n"
     ]
    }
   ],
   "source": [
    "import scipy\n",
    "#converting the matrix to densematrix\n",
    "final_dense=final_tf_idf.todense()#(4986, 12997)\n",
    "print(final_dense.shape)\n",
    "x=final_dense\n",
    "\n",
    "\n",
    "#converting score into Postive and negative review\n",
    "def df_score(x):\n",
    "    if x<3:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n",
    "    \n",
    "y = final['Score'].apply(df_score)\n",
    "\n",
    "y=y.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6eBTrer9CAay"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train_shape :  2991\n",
      "y_train_shape :  2991\n",
      "x_cv_shape :  997\n",
      "y_cv_shape :  997\n",
      "x_test_shape :  998\n",
      "y_test_shape :  998\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "#spliting the data into train,cv and test. \n",
    "x_train,x_1,y_train,y_1=train_test_split(x,y,train_size =0.6,random_state=0)\n",
    "x_cv,x_test,y_cv,y_test=train_test_split(x_1,y_1,train_size =0.5,random_state=0)\n",
    "\n",
    "\n",
    "#priting the rows against train,cv and test\n",
    "print(\"x_train_shape : \", x_train.shape[0])\n",
    "print(\"y_train_shape : \", y_train.shape[0])\n",
    "print(\"x_cv_shape : \", x_cv.shape[0])\n",
    "print(\"y_cv_shape : \", y_cv.shape[0])\n",
    "print(\"x_test_shape : \", x_test.shape[0])\n",
    "print(\"y_test_shape : \", y_test.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of the model for Cross validation optimal-K: 5 is 85.07014028056112 \n"
     ]
    }
   ],
   "source": [
    "CV_Accuracy=dict()#making the dict. \n",
    "for k in range(1,30):\n",
    "    knn=KNeighborsClassifier(n_neighbors=k,algorithm='brute')#calling the Knn classifiers. \n",
    "    knn.fit(x_train,y_train)#fiting with Dtrain data \n",
    "    pred=knn.predict(x_cv)#predicting the label values with CV data\n",
    "    acc=accuracy_score(y_cv,pred)*float(100) #finding the accurarcy.\n",
    "    CV_Accuracy[k]=acc#storing the key valye pairs of K and accuracy. \n",
    "    \n",
    "#getting the optimal Value    \n",
    "optimal_k=max(CV_Accuracy,key=CV_Accuracy.get)\n",
    "\n",
    "#calling the Knn classifier with optimal value.\n",
    "knn=KNeighborsClassifier(n_neighbors=optimal_k,algorithm='brute')\n",
    "knn.fit(x_train,y_train)#fiting with Dtest data\n",
    "pred=knn.predict(x_test)#predicting the label values with Dtest\n",
    "acc=accuracy_score(y_test,pred)*float(100)#finding the accuracy. \n",
    "print(\"The accuracy of the model for Cross validation optimal-K: {0} is {1} \".format(optimal_k,acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zln2L0SUCAa0"
   },
   "source": [
    "### [5.1.3] Applying KNN brute force on AVG W2V,<font color='red'> SET 3</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-YnpPa54CAa0"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "#converting the matrix to densematrix\n",
    "x = sent_vectors\n",
    "\n",
    "#converting score into Postive and negative review\n",
    "def df_score(x):\n",
    "    if x<3:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n",
    "    \n",
    "y = final['Score'].apply(df_score)\n",
    "\n",
    "y=y.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train_total rows :  2991\n",
      "y_train_total rows :  2991\n",
      "x_cv_total rows :  997\n",
      "y_cv_total rows :  997\n",
      "x_test_total rows :  998\n",
      "y_test_total rows :  998\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "#spliting the data into train,cv and test. \n",
    "x_train,x_1,y_train,y_1=train_test_split(x,y,train_size =0.6,random_state=0)\n",
    "x_cv,x_test,y_cv,y_test=train_test_split(x_1,y_1,train_size =0.5,random_state=0)\n",
    "\n",
    "\n",
    "#priting the rows against train,cv and test\n",
    "print(\"x_train_total rows : \", len(x_train))\n",
    "print(\"y_train_total rows : \", len(y_train))\n",
    "print(\"x_cv_total rows : \", len(x_cv))\n",
    "print(\"y_cv_total rows : \", len(y_cv))\n",
    "print(\"x_test_total rows : \", len(x_test))\n",
    "print(\"y_test_total rows : \", len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of the model for Cross validation optimal-K 19 is 84.66933867735472 \n"
     ]
    }
   ],
   "source": [
    "CV_Accuracy=dict()#making the dict. \n",
    "for k in range(1,30):\n",
    "    knn=KNeighborsClassifier(n_neighbors=k,algorithm='brute')#calling the Knn classifiers. \n",
    "    knn.fit(x_train,y_train)#fiting with Dtrain data \n",
    "    pred=knn.predict(x_cv)#predicting the label values with CV data\n",
    "    acc=accuracy_score(y_cv,pred)*float(100) #finding the accurarcy.\n",
    "    CV_Accuracy[k]=acc#storing the key valye pairs of K and accuracy. \n",
    "    \n",
    "#getting the optimal Value    \n",
    "optimal_k=max(CV_Accuracy,key=CV_Accuracy.get)\n",
    "\n",
    "#calling the Knn classifier with optimal value.\n",
    "knn=KNeighborsClassifier(n_neighbors=optimal_k,algorithm='brute')\n",
    "knn.fit(x_train,y_train)#fiting with Dtest data\n",
    "pred=knn.predict(x_test)#predicting the label values with Dtest\n",
    "acc=accuracy_score(y_test,pred)*float(100)#finding the accuracy. \n",
    "print(\"The accuracy of the model for Cross validation optimal-K {0} is {1} \".format(optimal_k,acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RBaVF4aHCAa4"
   },
   "source": [
    "### [5.1.4] Applying KNN brute force on TFIDF W2V,<font color='red'> SET 4</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xYysToufCAa4"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "#converting the matrix to densematrix\n",
    "x = tfidf_sent_vectors\n",
    "\n",
    "#converting score into Postive and negative review\n",
    "def df_score(x):\n",
    "    if x<3:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n",
    "    \n",
    "y = final['Score'].apply(df_score)\n",
    "\n",
    "y=y.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train_total rows :  2991\n",
      "y_train_total rows :  2991\n",
      "x_cv_total rows :  997\n",
      "y_cv_total rows :  997\n",
      "x_test_total rows :  998\n",
      "y_test_total rows :  998\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "#spliting the data into train,cv and test. \n",
    "x_train,x_1,y_train,y_1=train_test_split(x,y,train_size =0.6,random_state=0)\n",
    "x_cv,x_test,y_cv,y_test=train_test_split(x_1,y_1,train_size =0.5,random_state=0)\n",
    "\n",
    "\n",
    "#priting the rows against train,cv and test\n",
    "print(\"x_train_total rows : \", len(x_train))\n",
    "print(\"y_train_total rows : \", len(y_train))\n",
    "print(\"x_cv_total rows : \", len(x_cv))\n",
    "print(\"y_cv_total rows : \", len(y_cv))\n",
    "print(\"x_test_total rows : \", len(x_test))\n",
    "print(\"y_test_total rows : \", len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of the model for Cross validation optimal-K 13 is 84.96993987975952 \n"
     ]
    }
   ],
   "source": [
    "CV_Accuracy=dict()#making the dict. \n",
    "for k in range(1,30):\n",
    "    knn=KNeighborsClassifier(n_neighbors=k,algorithm='brute')#calling the Knn classifiers. \n",
    "    knn.fit(x_train,y_train)#fiting with Dtrain data \n",
    "    pred=knn.predict(x_cv)#predicting the label values with CV data\n",
    "    acc=accuracy_score(y_cv,pred)*float(100) #finding the accurarcy.\n",
    "    CV_Accuracy[k]=acc#storing the key valye pairs of K and accuracy. \n",
    "    \n",
    "#getting the optimal Value    \n",
    "optimal_k=max(CV_Accuracy,key=CV_Accuracy.get)\n",
    "\n",
    "#calling the Knn classifier with optimal value.\n",
    "knn=KNeighborsClassifier(n_neighbors=optimal_k,algorithm='brute')\n",
    "knn.fit(x_train,y_train)#fiting with Dtest data\n",
    "pred=knn.predict(x_test)#predicting the label values with Dtest\n",
    "acc=accuracy_score(y_test,pred)*float(100)#finding the accuracy. \n",
    "print(\"The accuracy of the model for Cross validation optimal-K {0} is {1} \".format(optimal_k,acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [5.2] Applying KNN kd-tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [5.2.1] Applying KNN kd-tree on BOW,<font color='red'> SET 5</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4986, 12997)\n"
     ]
    }
   ],
   "source": [
    "import scipy\n",
    "#converting the matrix to densematrix\n",
    "final_dense=final_counts.todense()#(4986, 12997)\n",
    "print(final_dense.shape)\n",
    "x=final_dense\n",
    "\n",
    "\n",
    "#converting score into Postive and negative review\n",
    "def df_score(x):\n",
    "    if x<3:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n",
    "    \n",
    "y = final['Score'].apply(df_score)\n",
    "\n",
    "y=y.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train_shape :  2991\n",
      "y_train_shape :  2991\n",
      "x_cv_shape :  997\n",
      "y_cv_shape :  997\n",
      "x_test_shape :  998\n",
      "y_test_shape :  998\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "#spliting the data into train,cv and test. \n",
    "x_train,x_1,y_train,y_1=train_test_split(x,y,train_size =0.6,random_state=0)\n",
    "x_cv,x_test,y_cv,y_test=train_test_split(x_1,y_1,train_size =0.5,random_state=0)\n",
    "\n",
    "\n",
    "#priting the rows against train,cv and test\n",
    "print(\"x_train_shape : \", x_train.shape[0])\n",
    "print(\"y_train_shape : \", y_train.shape[0])\n",
    "print(\"x_cv_shape : \", x_cv.shape[0])\n",
    "print(\"y_cv_shape : \", y_cv.shape[0])\n",
    "print(\"x_test_shape : \", x_test.shape[0])\n",
    "print(\"y_test_shape : \", y_test.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of the model for Cross validation optimal-K: 7 is 84.5691382765531 \n"
     ]
    }
   ],
   "source": [
    "CV_Accuracy=dict()#making the dict. \n",
    "for k in range(1,20):\n",
    "    knn=KNeighborsClassifier(n_neighbors=k,algorithm='kd_tree')#calling the Knn classifiers. \n",
    "    knn.fit(x_train,y_train)#fiting with Dtrain data \n",
    "    pred=knn.predict(x_cv)#predicting the label values with CV data\n",
    "    acc=accuracy_score(y_cv,pred)*float(100) #finding the accurarcy.\n",
    "    CV_Accuracy[k]=acc#storing the key valye pairs of K and accuracy. \n",
    "    \n",
    "#getting the optimal Value    \n",
    "optimal_k=max(CV_Accuracy,key=CV_Accuracy.get)\n",
    "\n",
    "#calling the Knn classifier with optimal value.\n",
    "knn=KNeighborsClassifier(n_neighbors=optimal_k,algorithm='kd_tree')\n",
    "knn.fit(x_train,y_train)#fiting with Dtest data\n",
    "pred=knn.predict(x_test)#predicting the label values with Dtest\n",
    "acc=accuracy_score(y_test,pred)*float(100)#finding the accuracy. \n",
    "print(\"The accuracy of the model for Cross validation optimal-K: {0} is {1} \".format(optimal_k,acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [5.2.2] Applying KNN kd-tree on TFIDF,<font color='red'> SET 6</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4986, 3144)\n"
     ]
    }
   ],
   "source": [
    "import scipy\n",
    "#converting the matrix to densematrix\n",
    "final_dense=final_tf_idf.todense()#(4986, 12997)\n",
    "print(final_dense.shape)\n",
    "x=final_dense\n",
    "\n",
    "\n",
    "#converting score into Postive and negative review\n",
    "def df_score(x):\n",
    "    if x<3:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n",
    "    \n",
    "y = final['Score'].apply(df_score)\n",
    "\n",
    "y=y.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train_shape :  2991\n",
      "y_train_shape :  2991\n",
      "x_cv_shape :  997\n",
      "y_cv_shape :  997\n",
      "x_test_shape :  998\n",
      "y_test_shape :  998\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "#spliting the data into train,cv and test. \n",
    "x_train,x_1,y_train,y_1=train_test_split(x,y,train_size =0.6,random_state=0)\n",
    "x_cv,x_test,y_cv,y_test=train_test_split(x_1,y_1,train_size =0.5,random_state=0)\n",
    "\n",
    "\n",
    "#priting the rows against train,cv and test\n",
    "print(\"x_train_shape : \", x_train.shape[0])\n",
    "print(\"y_train_shape : \", y_train.shape[0])\n",
    "print(\"x_cv_shape : \", x_cv.shape[0])\n",
    "print(\"y_cv_shape : \", y_cv.shape[0])\n",
    "print(\"x_test_shape : \", x_test.shape[0])\n",
    "print(\"y_test_shape : \", y_test.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of the model for Cross validation optimal-K: 5 is 85.07014028056112 \n"
     ]
    }
   ],
   "source": [
    "CV_Accuracy=dict()#making the dict. \n",
    "for k in range(1,20):\n",
    "    knn=KNeighborsClassifier(n_neighbors=k,algorithm='kd_tree')#calling the Knn classifiers. \n",
    "    knn.fit(x_train,y_train)#fiting with Dtrain data \n",
    "    pred=knn.predict(x_cv)#predicting the label values with CV data\n",
    "    acc=accuracy_score(y_cv,pred)*float(100) #finding the accurarcy.\n",
    "    CV_Accuracy[k]=acc#storing the key valye pairs of K and accuracy. \n",
    "    \n",
    "#getting the optimal Value    \n",
    "optimal_k=max(CV_Accuracy,key=CV_Accuracy.get)\n",
    "\n",
    "#calling the Knn classifier with optimal value.\n",
    "knn=KNeighborsClassifier(n_neighbors=optimal_k,algorithm='kd_tree')\n",
    "knn.fit(x_train,y_train)#fiting with Dtest data\n",
    "pred=knn.predict(x_test)#predicting the label values with Dtest\n",
    "acc=accuracy_score(y_test,pred)*float(100)#finding the accuracy. \n",
    "print(\"The accuracy of the model for Cross validation optimal-K: {0} is {1} \".format(optimal_k,acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [5.2.3] Applying KNN kd-tree on AVG W2V,<font color='red'> SET 7</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "#converting the matrix to densematrix\n",
    "x = sent_vectors\n",
    "\n",
    "#converting score into Postive and negative review\n",
    "def df_score(x):\n",
    "    if x<3:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n",
    "    \n",
    "y = final['Score'].apply(df_score)\n",
    "\n",
    "y=y.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train_total rows :  2991\n",
      "y_train_total rows :  2991\n",
      "x_cv_total rows :  997\n",
      "y_cv_total rows :  997\n",
      "x_test_total rows :  998\n",
      "y_test_total rows :  998\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "#spliting the data into train,cv and test. \n",
    "x_train,x_1,y_train,y_1=train_test_split(x,y,train_size =0.6,random_state=0)\n",
    "x_cv,x_test,y_cv,y_test=train_test_split(x_1,y_1,train_size =0.5,random_state=0)\n",
    "\n",
    "\n",
    "#priting the rows against train,cv and test\n",
    "print(\"x_train_total rows : \", len(x_train))\n",
    "print(\"y_train_total rows : \", len(y_train))\n",
    "print(\"x_cv_total rows : \", len(x_cv))\n",
    "print(\"y_cv_total rows : \", len(y_cv))\n",
    "print(\"x_test_total rows : \", len(x_test))\n",
    "print(\"y_test_total rows : \", len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of the model for Cross validation optimal-K 19 is 84.66933867735472 \n"
     ]
    }
   ],
   "source": [
    "CV_Accuracy=dict()#making the dict. \n",
    "for k in range(1,30):\n",
    "    knn=KNeighborsClassifier(n_neighbors=k,algorithm='kd_tree')#calling the Knn classifiers. \n",
    "    knn.fit(x_train,y_train)#fiting with Dtrain data \n",
    "    pred=knn.predict(x_cv)#predicting the label values with CV data\n",
    "    acc=accuracy_score(y_cv,pred)*float(100) #finding the accurarcy.\n",
    "    CV_Accuracy[k]=acc#storing the key valye pairs of K and accuracy. \n",
    "    \n",
    "#getting the optimal Value    \n",
    "optimal_k=max(CV_Accuracy,key=CV_Accuracy.get)\n",
    "\n",
    "#calling the Knn classifier with optimal value.\n",
    "knn=KNeighborsClassifier(n_neighbors=optimal_k,algorithm='kd_tree')\n",
    "knn.fit(x_train,y_train)#fiting with Dtest data\n",
    "pred=knn.predict(x_test)#predicting the label values with Dtest\n",
    "acc=accuracy_score(y_test,pred)*float(100)#finding the accuracy. \n",
    "print(\"The accuracy of the model for Cross validation optimal-K {0} is {1} \".format(optimal_k,acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [5.2.4] Applying KNN kd-tree on TFIDF W2V,<font color='red'> SET 4</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "#converting the matrix to densematrix\n",
    "x = tfidf_sent_vectors\n",
    "\n",
    "#converting score into Postive and negative review\n",
    "def df_score(x):\n",
    "    if x<3:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n",
    "    \n",
    "y = final['Score'].apply(df_score)\n",
    "\n",
    "y=y.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train_total rows :  2991\n",
      "y_train_total rows :  2991\n",
      "x_cv_total rows :  997\n",
      "y_cv_total rows :  997\n",
      "x_test_total rows :  998\n",
      "y_test_total rows :  998\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "#spliting the data into train,cv and test. \n",
    "x_train,x_1,y_train,y_1=train_test_split(x,y,train_size =0.6,random_state=0)\n",
    "x_cv,x_test,y_cv,y_test=train_test_split(x_1,y_1,train_size =0.5,random_state=0)\n",
    "\n",
    "\n",
    "#priting the rows against train,cv and test\n",
    "print(\"x_train_total rows : \", len(x_train))\n",
    "print(\"y_train_total rows : \", len(y_train))\n",
    "print(\"x_cv_total rows : \", len(x_cv))\n",
    "print(\"y_cv_total rows : \", len(y_cv))\n",
    "print(\"x_test_total rows : \", len(x_test))\n",
    "print(\"y_test_total rows : \", len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of the model for Cross validation optimal-K 13 is 84.96993987975952 \n"
     ]
    }
   ],
   "source": [
    "CV_Accuracy=dict()#making the dict. \n",
    "for k in range(1,30):\n",
    "    knn=KNeighborsClassifier(n_neighbors=k,algorithm='kd_tree')#calling the Knn classifiers. \n",
    "    knn.fit(x_train,y_train)#fiting with Dtrain data \n",
    "    pred=knn.predict(x_cv)#predicting the label values with CV data\n",
    "    acc=accuracy_score(y_cv,pred)*float(100) #finding the accurarcy.\n",
    "    CV_Accuracy[k]=acc#storing the key valye pairs of K and accuracy. \n",
    "    \n",
    "#getting the optimal Value    \n",
    "optimal_k=max(CV_Accuracy,key=CV_Accuracy.get)\n",
    "\n",
    "#calling the Knn classifier with optimal value.\n",
    "knn=KNeighborsClassifier(n_neighbors=optimal_k,algorithm='kd_tree')\n",
    "knn.fit(x_train,y_train)#fiting with Dtest data\n",
    "pred=knn.predict(x_test)#predicting the label values with Dtest\n",
    "acc=accuracy_score(y_test,pred)*float(100)#finding the accuracy. \n",
    "print(\"The accuracy of the model for Cross validation optimal-K {0} is {1} \".format(optimal_k,acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 1 0]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "fpr, tpr, thresholds = metrics.roc_curve(y_test,pred,pos_label=2)\n",
    "\n",
    "auc=metrics.auc(fpr, tpr)\n",
    "\n",
    "print(thresholds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jilexiiyCAa6"
   },
   "source": [
    "# [6] Conclusions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TroM2UQUCAa7"
   },
   "outputs": [],
   "source": [
    "# Write few sentance about the results that you got and observation that you did from the analysis"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "9amw6tMZCAaL",
    "1dhfJZ7ZCAaR",
    "F--Xk5fhCAaV",
    "XnzP-eZdCAaa",
    "EPjGCg7UCAag",
    "oPxfYXhMCAag",
    "sKAEsZZLCAam",
    "ejF91OEjCAaw",
    "b_-boR2SCAay",
    "zln2L0SUCAa0",
    "RBaVF4aHCAa4"
   ],
   "name": "02 Amazon Fine Food Reviews Analysis_TSNE.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
